<!-- HTML header for doxygen 1.8.13-->
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.9.2"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>PSOC E8XXGP Device Support Library</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="resize.js"></script>
<script type="text/javascript" src="navtreedata.js"></script>
<script type="text/javascript" src="navtree.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen_style.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectlogo"><a href="http://www.cypress.com/"><img alt="Logo" src="logo.png"/></a></td>
  <td id="projectalign" style="padding-left: 0.5em;">
   <div id="projectname">PSOC E8XXGP Device Support Library</div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.9.2 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
var searchBox = new SearchBox("searchBox", "search",'Search','.html');
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
/* @license-end */
</script>
<div id="main-nav"></div>
</div><!-- top -->
<div id="side-nav" class="ui-resizable side-nav-resizable">
  <div id="nav-tree">
    <div id="nav-tree-contents">
      <div id="nav-sync" class="sync"></div>
    </div>
  </div>
  <div id="splitbar" style="-moz-user-select:none;"
       class="ui-resizable-handle">
  </div>
</div>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(document).ready(function(){initNavTree('group__group__nn__kernel__functions.html',''); initResizable(); });
/* @license-end */
</script>
<div id="doc-content">
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0"
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div class="header">
  <div class="summary">
<a href="#func-members">Functions</a>  </div>
  <div class="headertitle"><div class="title">functions<div class="ingroups"><a class="el" href="group__group__nn__kernel.html">NNLITE HW Accelerator KERNEL LIB</a></div></div></div>
</div><!--header-->
<div class="contents">
<a name="details" id="details"></a><h2 class="groupheader">General Description</h2>
<table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a id="func-members" name="func-members"></a>
Functions</h2></td></tr>
<tr class="memitem:gaaf6614a4ce7494a3107cb1163b297953"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group__group__nn__kernel__functions.html#gaaf6614a4ce7494a3107cb1163b297953">Cy_NNLite_LeakyRelUPWLActivation</a> (float alpha_scale, float unit_scale, <a class="el" href="group__group__nn__kernel__data__structures.html#structcy__nn__act__intrpl__param__t">cy_nn_act_intrpl_param_t</a> *leakyRelU)</td></tr>
<tr class="memdesc:gaaf6614a4ce7494a3107cb1163b297953"><td class="mdescLeft">&#160;</td><td class="mdescRight">Set PWL interpolation parameters for LeakyRElU activation.  <a href="group__group__nn__kernel__functions.html#gaaf6614a4ce7494a3107cb1163b297953">More...</a><br /></td></tr>
<tr class="separator:gaaf6614a4ce7494a3107cb1163b297953"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga61dad25009def8305d3c1158aca22656"><td class="memItemLeft" align="right" valign="top"><a class="el" href="group__group__nnlite__enums.html#ga8714c4a5105d4130fb67c76b0d9a1920">cy_en_nnlite_status_t</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group__group__nn__kernel__functions.html#ga61dad25009def8305d3c1158aca22656">Cy_NNLite_Convolution</a> (const int8_t *inputData, int8_t *outData, const <a class="el" href="group__group__nn__kernel__data__structures.html#structcy__nn__dims__t">cy_nn_dims_t</a> *inputDims, const <a class="el" href="group__group__nn__kernel__data__structures.html#structcy__nn__dims__t">cy_nn_dims_t</a> *outputDims, const <a class="el" href="group__group__nn__kernel__data__structures.html#structcy__nn__dims__t">cy_nn_dims_t</a> *filterDims, const int8_t *filterData, const int32_t *biasData, <a class="el" href="group__group__nn__kernel__data__structures.html#structcy__nn__conv__params__t">cy_nn_conv_params_t</a> *convParam, <a class="el" href="group__group__nnlite__enums.html#ga384cb7d2feea111076bbd75ae43e60f6">cy_en_nnlite_fused_activation_t</a> actType, <a class="el" href="group__group__nn__kernel__data__structures.html#structcy__nn__act__intrpl__param__t">cy_nn_act_intrpl_param_t</a> *intrplParam)</td></tr>
<tr class="memdesc:ga61dad25009def8305d3c1158aca22656"><td class="mdescLeft">&#160;</td><td class="mdescRight">2D Convolution CPU mode kernel API, API will configure nnlite and then start nnlite operation.API will work in blocking mode if callback function in Kernel config structure is NULL, if valid callback function is passed in Kernel config, API will be non-blocking and callback function will be called after completion of layer, caller need to wait for callback function before calling another Kernel API, else error will be for other function  <a href="group__group__nn__kernel__functions.html#ga61dad25009def8305d3c1158aca22656">More...</a><br /></td></tr>
<tr class="separator:ga61dad25009def8305d3c1158aca22656"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga6c81f67a76e5ba45c648a9538fb988cb"><td class="memItemLeft" align="right" valign="top"><a class="el" href="group__group__nnlite__enums.html#ga8714c4a5105d4130fb67c76b0d9a1920">cy_en_nnlite_status_t</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group__group__nn__kernel__functions.html#ga6c81f67a76e5ba45c648a9538fb988cb">Cy_NNLite_ConvolutionDMA</a> (const int8_t *inputData, int8_t *outData, const <a class="el" href="group__group__nn__kernel__data__structures.html#structcy__nn__dims__t">cy_nn_dims_t</a> *inputDims, const <a class="el" href="group__group__nn__kernel__data__structures.html#structcy__nn__dims__t">cy_nn_dims_t</a> *outputDims, const <a class="el" href="group__group__nn__kernel__data__structures.html#structcy__nn__dims__t">cy_nn_dims_t</a> *filterDims, const int8_t *filterData, const int32_t *biasData, <a class="el" href="group__group__nn__kernel__data__structures.html#structcy__nn__conv__params__t">cy_nn_conv_params_t</a> *convParam, <a class="el" href="group__group__nnlite__enums.html#ga384cb7d2feea111076bbd75ae43e60f6">cy_en_nnlite_fused_activation_t</a> actType, <a class="el" href="group__group__nn__kernel__data__structures.html#structcy__nn__act__intrpl__param__t">cy_nn_act_intrpl_param_t</a> *intrplParam)</td></tr>
<tr class="memdesc:ga6c81f67a76e5ba45c648a9538fb988cb"><td class="mdescLeft">&#160;</td><td class="mdescRight">2D Convolution DMA mode kernel API, API will configure DMA descriptor pointing nnlite MEMIO configuration structure.  <a href="group__group__nn__kernel__functions.html#ga6c81f67a76e5ba45c648a9538fb988cb">More...</a><br /></td></tr>
<tr class="separator:ga6c81f67a76e5ba45c648a9538fb988cb"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:gaa801087a50601af4eb3c57a0e5065ed0"><td class="memItemLeft" align="right" valign="top"><a class="el" href="group__group__nnlite__enums.html#ga8714c4a5105d4130fb67c76b0d9a1920">cy_en_nnlite_status_t</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group__group__nn__kernel__functions.html#gaa801087a50601af4eb3c57a0e5065ed0">Cy_NNLite_DepthwiseConvolution</a> (const int8_t *inputData, int8_t *outData, const <a class="el" href="group__group__nn__kernel__data__structures.html#structcy__nn__dims__t">cy_nn_dims_t</a> *inputDims, const <a class="el" href="group__group__nn__kernel__data__structures.html#structcy__nn__dims__t">cy_nn_dims_t</a> *outputDims, const <a class="el" href="group__group__nn__kernel__data__structures.html#structcy__nn__dims__t">cy_nn_dims_t</a> *filterDims, const int8_t *filterData, const int32_t *biasData, <a class="el" href="group__group__nn__kernel__data__structures.html#structcy__nn__conv__params__t">cy_nn_conv_params_t</a> *convParam, <a class="el" href="group__group__nnlite__enums.html#ga384cb7d2feea111076bbd75ae43e60f6">cy_en_nnlite_fused_activation_t</a> actType, <a class="el" href="group__group__nn__kernel__data__structures.html#structcy__nn__act__intrpl__param__t">cy_nn_act_intrpl_param_t</a> *intrplParam)</td></tr>
<tr class="memdesc:gaa801087a50601af4eb3c57a0e5065ed0"><td class="mdescLeft">&#160;</td><td class="mdescRight">Depthwise Convolution CPU mode kernel API, API will work in blocking mode if callback function in Kernel config structure is NULL, if valid callback function is passed in Kernel config, API will be non-blocking and callback function will be called after completion of layer, caller need to wait for callback function before calling another Kernel API, else error will be for other function.  <a href="group__group__nn__kernel__functions.html#gaa801087a50601af4eb3c57a0e5065ed0">More...</a><br /></td></tr>
<tr class="separator:gaa801087a50601af4eb3c57a0e5065ed0"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga2f4ffd40f54b17d26a70975ce828a199"><td class="memItemLeft" align="right" valign="top"><a class="el" href="group__group__nnlite__enums.html#ga8714c4a5105d4130fb67c76b0d9a1920">cy_en_nnlite_status_t</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group__group__nn__kernel__functions.html#ga2f4ffd40f54b17d26a70975ce828a199">Cy_NNLite_DepthwiseConvolutionDMA</a> (const int8_t *inputData, int8_t *outData, const <a class="el" href="group__group__nn__kernel__data__structures.html#structcy__nn__dims__t">cy_nn_dims_t</a> *inputDims, const <a class="el" href="group__group__nn__kernel__data__structures.html#structcy__nn__dims__t">cy_nn_dims_t</a> *outputDims, const <a class="el" href="group__group__nn__kernel__data__structures.html#structcy__nn__dims__t">cy_nn_dims_t</a> *filterDims, const int8_t *filterData, const int32_t *biasData, <a class="el" href="group__group__nn__kernel__data__structures.html#structcy__nn__conv__params__t">cy_nn_conv_params_t</a> *convParam, <a class="el" href="group__group__nnlite__enums.html#ga384cb7d2feea111076bbd75ae43e60f6">cy_en_nnlite_fused_activation_t</a> actType, <a class="el" href="group__group__nn__kernel__data__structures.html#structcy__nn__act__intrpl__param__t">cy_nn_act_intrpl_param_t</a> *intrplParam)</td></tr>
<tr class="memdesc:ga2f4ffd40f54b17d26a70975ce828a199"><td class="mdescLeft">&#160;</td><td class="mdescRight">Depthwise DMA mode kernel API, API will configure DMA descriptor pointing nnlite MEMIO configuration structure.  <a href="group__group__nn__kernel__functions.html#ga2f4ffd40f54b17d26a70975ce828a199">More...</a><br /></td></tr>
<tr class="separator:ga2f4ffd40f54b17d26a70975ce828a199"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:gabf4acdda27e317c08d7c11bdb9631e4c"><td class="memItemLeft" align="right" valign="top"><a class="el" href="group__group__nnlite__enums.html#ga8714c4a5105d4130fb67c76b0d9a1920">cy_en_nnlite_status_t</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group__group__nn__kernel__functions.html#gabf4acdda27e317c08d7c11bdb9631e4c">Cy_NNLite_FullyConnected</a> (const int8_t *inputData, int8_t *outData, const <a class="el" href="group__group__nn__kernel__data__structures.html#structcy__nn__dims__t">cy_nn_dims_t</a> *inputDims, const <a class="el" href="group__group__nn__kernel__data__structures.html#structcy__nn__dims__t">cy_nn_dims_t</a> *outputDims, const <a class="el" href="group__group__nn__kernel__data__structures.html#structcy__nn__dims__t">cy_nn_dims_t</a> *filterDims, const int8_t *filterData, const int32_t *biasData, <a class="el" href="group__group__nn__kernel__data__structures.html#structcy__nn__fc__params__t">cy_nn_fc_params_t</a> *fcParam, <a class="el" href="group__group__nnlite__enums.html#ga384cb7d2feea111076bbd75ae43e60f6">cy_en_nnlite_fused_activation_t</a> actType, <a class="el" href="group__group__nn__kernel__data__structures.html#structcy__nn__act__intrpl__param__t">cy_nn_act_intrpl_param_t</a> *intrplParam)</td></tr>
<tr class="memdesc:gabf4acdda27e317c08d7c11bdb9631e4c"><td class="mdescLeft">&#160;</td><td class="mdescRight">Fully connected CPU mode kernel API, API will configure nnlite and then start nnlite operation.API will work in blocking mode For case inputDims-&gt;dims[0] &gt; 1,scratch buffer is required scratch buffer size in CPU should be calculated using Cy_NNLite_FC_ScratchBufSize API if callback function in Kernel config structure is NULL, if valid callback function is passed in Kernel config, API will be non-blocking and callback function will be called after completion of layer, caller need to wait for callback function before calling another Kernel API, else error will be for other function.  <a href="group__group__nn__kernel__functions.html#gabf4acdda27e317c08d7c11bdb9631e4c">More...</a><br /></td></tr>
<tr class="separator:gabf4acdda27e317c08d7c11bdb9631e4c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:gabdfe1b52e4e3129cd6baa93f81236150"><td class="memItemLeft" align="right" valign="top"><a class="el" href="group__group__nnlite__enums.html#ga8714c4a5105d4130fb67c76b0d9a1920">cy_en_nnlite_status_t</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group__group__nn__kernel__functions.html#gabdfe1b52e4e3129cd6baa93f81236150">Cy_NNLite_FullyConnectedDMA</a> (const int8_t *inputData, int8_t *outData, const <a class="el" href="group__group__nn__kernel__data__structures.html#structcy__nn__dims__t">cy_nn_dims_t</a> *inputDims, const <a class="el" href="group__group__nn__kernel__data__structures.html#structcy__nn__dims__t">cy_nn_dims_t</a> *outputDims, const <a class="el" href="group__group__nn__kernel__data__structures.html#structcy__nn__dims__t">cy_nn_dims_t</a> *filterDims, const int8_t *filterData, const int32_t *biasData, <a class="el" href="group__group__nn__kernel__data__structures.html#structcy__nn__fc__params__t">cy_nn_fc_params_t</a> *fcParam, <a class="el" href="group__group__nnlite__enums.html#ga384cb7d2feea111076bbd75ae43e60f6">cy_en_nnlite_fused_activation_t</a> actType, <a class="el" href="group__group__nn__kernel__data__structures.html#structcy__nn__act__intrpl__param__t">cy_nn_act_intrpl_param_t</a> *intrplParam)</td></tr>
<tr class="memdesc:gabdfe1b52e4e3129cd6baa93f81236150"><td class="mdescLeft">&#160;</td><td class="mdescRight">Fully connected DMA mode kernel API, API will configure DMA descriptor pointing nnlite MEMIO configuration structure.  <a href="group__group__nn__kernel__functions.html#gabdfe1b52e4e3129cd6baa93f81236150">More...</a><br /></td></tr>
<tr class="separator:gabdfe1b52e4e3129cd6baa93f81236150"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:gac23235aca7d94134af544c0e6ffe46d5"><td class="memItemLeft" align="right" valign="top"><a class="el" href="group__group__nnlite__enums.html#ga8714c4a5105d4130fb67c76b0d9a1920">cy_en_nnlite_status_t</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group__group__nn__kernel__functions.html#gac23235aca7d94134af544c0e6ffe46d5">Cy_NNLite_Avgpool</a> (const int8_t *inputData, int8_t *outData, const <a class="el" href="group__group__nn__kernel__data__structures.html#structcy__nn__dims__t">cy_nn_dims_t</a> *inputDims, const <a class="el" href="group__group__nn__kernel__data__structures.html#structcy__nn__dims__t">cy_nn_dims_t</a> *outputDims, const <a class="el" href="group__group__nn__kernel__data__structures.html#structcy__nn__dims__t">cy_nn_dims_t</a> *filterDims, <a class="el" href="group__group__nn__kernel__data__structures.html#structcy__nn__pool__params__t">cy_nn_pool_params_t</a> *avgpoolParam)</td></tr>
<tr class="memdesc:gac23235aca7d94134af544c0e6ffe46d5"><td class="mdescLeft">&#160;</td><td class="mdescRight">Average pool CPU mode kernel API, API will configure nnlite.  <a href="group__group__nn__kernel__functions.html#gac23235aca7d94134af544c0e6ffe46d5">More...</a><br /></td></tr>
<tr class="separator:gac23235aca7d94134af544c0e6ffe46d5"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga02e850ef8f743ad3781e216f53e46ad4"><td class="memItemLeft" align="right" valign="top"><a class="el" href="group__group__nnlite__enums.html#ga8714c4a5105d4130fb67c76b0d9a1920">cy_en_nnlite_status_t</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group__group__nn__kernel__functions.html#ga02e850ef8f743ad3781e216f53e46ad4">Cy_NNLite_AvgpoolDMA</a> (const int8_t *inputData, int8_t *outData, const <a class="el" href="group__group__nn__kernel__data__structures.html#structcy__nn__dims__t">cy_nn_dims_t</a> *inputDims, const <a class="el" href="group__group__nn__kernel__data__structures.html#structcy__nn__dims__t">cy_nn_dims_t</a> *outputDims, const <a class="el" href="group__group__nn__kernel__data__structures.html#structcy__nn__dims__t">cy_nn_dims_t</a> *filterDims, <a class="el" href="group__group__nn__kernel__data__structures.html#structcy__nn__pool__params__t">cy_nn_pool_params_t</a> *avgpoolParam)</td></tr>
<tr class="memdesc:ga02e850ef8f743ad3781e216f53e46ad4"><td class="mdescLeft">&#160;</td><td class="mdescRight">Average pool CPU mode kernel API, API will configure DMA descriptor pointing nnlite MEMIO configuration structure.  <a href="group__group__nn__kernel__functions.html#ga02e850ef8f743ad3781e216f53e46ad4">More...</a><br /></td></tr>
<tr class="separator:ga02e850ef8f743ad3781e216f53e46ad4"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga7de6394709b01caddd5e1c9dbdbde3b4"><td class="memItemLeft" align="right" valign="top"><a class="el" href="group__group__nnlite__enums.html#ga8714c4a5105d4130fb67c76b0d9a1920">cy_en_nnlite_status_t</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group__group__nn__kernel__functions.html#ga7de6394709b01caddd5e1c9dbdbde3b4">Cy_NNLite_Maxpool</a> (const int8_t *inputData, int8_t *outData, const <a class="el" href="group__group__nn__kernel__data__structures.html#structcy__nn__dims__t">cy_nn_dims_t</a> *inputDims, const <a class="el" href="group__group__nn__kernel__data__structures.html#structcy__nn__dims__t">cy_nn_dims_t</a> *outputDims, const <a class="el" href="group__group__nn__kernel__data__structures.html#structcy__nn__dims__t">cy_nn_dims_t</a> *filterDims, <a class="el" href="group__group__nn__kernel__data__structures.html#structcy__nn__pool__params__t">cy_nn_pool_params_t</a> *poolParam)</td></tr>
<tr class="memdesc:ga7de6394709b01caddd5e1c9dbdbde3b4"><td class="mdescLeft">&#160;</td><td class="mdescRight">Max pool CPU mode kernel API, API will configure nnlite.  <a href="group__group__nn__kernel__functions.html#ga7de6394709b01caddd5e1c9dbdbde3b4">More...</a><br /></td></tr>
<tr class="separator:ga7de6394709b01caddd5e1c9dbdbde3b4"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:gab3d59e53baf9fc619c5be3b8ece86221"><td class="memItemLeft" align="right" valign="top"><a class="el" href="group__group__nnlite__enums.html#ga8714c4a5105d4130fb67c76b0d9a1920">cy_en_nnlite_status_t</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group__group__nn__kernel__functions.html#gab3d59e53baf9fc619c5be3b8ece86221">Cy_NNLite_MaxpoolDMA</a> (const int8_t *inputData, int8_t *outData, const <a class="el" href="group__group__nn__kernel__data__structures.html#structcy__nn__dims__t">cy_nn_dims_t</a> *inputDims, const <a class="el" href="group__group__nn__kernel__data__structures.html#structcy__nn__dims__t">cy_nn_dims_t</a> *outputDims, const <a class="el" href="group__group__nn__kernel__data__structures.html#structcy__nn__dims__t">cy_nn_dims_t</a> *filterDims, <a class="el" href="group__group__nn__kernel__data__structures.html#structcy__nn__pool__params__t">cy_nn_pool_params_t</a> *poolParam)</td></tr>
<tr class="memdesc:gab3d59e53baf9fc619c5be3b8ece86221"><td class="mdescLeft">&#160;</td><td class="mdescRight">Max pool CPU mode kernel API, API will configure DMA descriptor pointing nnlite MEMIO configuration structure.  <a href="group__group__nn__kernel__functions.html#gab3d59e53baf9fc619c5be3b8ece86221">More...</a><br /></td></tr>
<tr class="separator:gab3d59e53baf9fc619c5be3b8ece86221"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga1c8ba4f8b4baf9c33d9abebd583797ef"><td class="memItemLeft" align="right" valign="top"><a class="el" href="group__group__nnlite__enums.html#ga8714c4a5105d4130fb67c76b0d9a1920">cy_en_nnlite_status_t</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group__group__nn__kernel__functions.html#ga1c8ba4f8b4baf9c33d9abebd583797ef">Cy_NNLite_Scaling_Setup</a> (<a class="el" href="group__group__nn__kernel__data__structures.html#structcy__nn__scaling__t">cy_nn_scaling_t</a> *ss, float lhs_scale, float rhs_scale, float output_scale, <a class="el" href="group__group__nnlite__enums.html#gab1d317e2be183e109725321de8c31bdb">cy_en_nnlite_activation_size_t</a> input_size, <a class="el" href="group__group__nnlite__enums.html#ga12a9e134b477430f9d2562c18e7d3620">cy_en_nnlite_op_t</a> op_type, <a class="el" href="group__group__nnlite__enums.html#ga384cb7d2feea111076bbd75ae43e60f6">cy_en_nnlite_fused_activation_t</a> act_type)</td></tr>
<tr class="memdesc:ga1c8ba4f8b4baf9c33d9abebd583797ef"><td class="mdescLeft">&#160;</td><td class="mdescRight">Precomputation of NPU scaling factor settings for NPU binary operations.  <a href="group__group__nn__kernel__functions.html#ga1c8ba4f8b4baf9c33d9abebd583797ef">More...</a><br /></td></tr>
<tr class="separator:ga1c8ba4f8b4baf9c33d9abebd583797ef"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga3345c26bd760af24bc030099b7c4ebbc"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group__group__nn__kernel__functions.html#ga3345c26bd760af24bc030099b7c4ebbc">Cy_NNLite_Scaling_Q_Setup</a> (<a class="el" href="group__group__nn__kernel__data__structures.html#structcy__nn__scaling__t">cy_nn_scaling_t</a> *ss)</td></tr>
<tr class="memdesc:ga3345c26bd760af24bc030099b7c4ebbc"><td class="mdescLeft">&#160;</td><td class="mdescRight">Set scaling configuration to "no scaling" (fast)  <a href="group__group__nn__kernel__functions.html#ga3345c26bd760af24bc030099b7c4ebbc">More...</a><br /></td></tr>
<tr class="separator:ga3345c26bd760af24bc030099b7c4ebbc"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:gaffaef8a986e014bf3b106016d8297062"><td class="memItemLeft" align="right" valign="top"><a class="el" href="group__group__nnlite__enums.html#ga8714c4a5105d4130fb67c76b0d9a1920">cy_en_nnlite_status_t</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group__group__nn__kernel__functions.html#gaffaef8a986e014bf3b106016d8297062">Cy_NNLite_AddSubMul</a> (const int8_t *lhsData, const int8_t *rhsData, int8_t *outData, const <a class="el" href="group__group__nn__kernel__data__structures.html#structcy__nn__dims__t">cy_nn_dims_t</a> *lhsDims, const <a class="el" href="group__group__nn__kernel__data__structures.html#structcy__nn__dims__t">cy_nn_dims_t</a> *rhsOutDims, const <a class="el" href="group__group__nn__kernel__data__structures.html#structcy__nn__pwise__binary__params__t">cy_nn_pwise_binary_params_t</a> *pwParams, <a class="el" href="group__group__nnlite__enums.html#ga12a9e134b477430f9d2562c18e7d3620">cy_en_nnlite_op_t</a> op_type, <a class="el" href="group__group__nnlite__enums.html#ga384cb7d2feea111076bbd75ae43e60f6">cy_en_nnlite_fused_activation_t</a> act_type)</td></tr>
<tr class="memdesc:gaffaef8a986e014bf3b106016d8297062"><td class="mdescLeft">&#160;</td><td class="mdescRight">Generic binary op CPU mode kernel API, API will configure nnlite.  <a href="group__group__nn__kernel__functions.html#gaffaef8a986e014bf3b106016d8297062">More...</a><br /></td></tr>
<tr class="separator:gaffaef8a986e014bf3b106016d8297062"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:gab9f8f7bf974e85cc9f617db483922756"><td class="memItemLeft" align="right" valign="top"><a class="el" href="group__group__nnlite__enums.html#ga8714c4a5105d4130fb67c76b0d9a1920">cy_en_nnlite_status_t</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group__group__nn__kernel__functions.html#gab9f8f7bf974e85cc9f617db483922756">Cy_NNLite_AddSubMulDMA</a> (const int8_t *lhsData, const int8_t *rhsData, int8_t *outData, const <a class="el" href="group__group__nn__kernel__data__structures.html#structcy__nn__dims__t">cy_nn_dims_t</a> *lhsDims, const <a class="el" href="group__group__nn__kernel__data__structures.html#structcy__nn__dims__t">cy_nn_dims_t</a> *rhsOutDims, const <a class="el" href="group__group__nn__kernel__data__structures.html#structcy__nn__pwise__binary__params__t">cy_nn_pwise_binary_params_t</a> *pwParams, <a class="el" href="group__group__nnlite__enums.html#ga12a9e134b477430f9d2562c18e7d3620">cy_en_nnlite_op_t</a> op_type, <a class="el" href="group__group__nnlite__enums.html#ga384cb7d2feea111076bbd75ae43e60f6">cy_en_nnlite_fused_activation_t</a> act_type)</td></tr>
<tr class="memdesc:gab9f8f7bf974e85cc9f617db483922756"><td class="mdescLeft">&#160;</td><td class="mdescRight">Generic binary op CPU mode kernel API, API will configure DMA descriptor pointing nnlite MEMIO configuration structure.  <a href="group__group__nn__kernel__functions.html#gab9f8f7bf974e85cc9f617db483922756">More...</a><br /></td></tr>
<tr class="separator:gab9f8f7bf974e85cc9f617db483922756"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga1a1c20d1fd2b23d54ea782ccfb2e277d"><td class="memItemLeft" align="right" valign="top"><a class="el" href="group__group__nnlite__enums.html#ga8714c4a5105d4130fb67c76b0d9a1920">cy_en_nnlite_status_t</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group__group__nn__kernel__functions.html#ga1a1c20d1fd2b23d54ea782ccfb2e277d">Cy_NNLite_Add</a> (const int8_t *lhsData, const int8_t *rhsData, int8_t *outData, const <a class="el" href="group__group__nn__kernel__data__structures.html#structcy__nn__dims__t">cy_nn_dims_t</a> *lhsDims, const <a class="el" href="group__group__nn__kernel__data__structures.html#structcy__nn__dims__t">cy_nn_dims_t</a> *rhsOutDims, const <a class="el" href="group__group__nn__kernel__data__structures.html#structcy__nn__pwise__binary__params__t">cy_nn_pwise_binary_params_t</a> *pwParams)</td></tr>
<tr class="memdesc:ga1a1c20d1fd2b23d54ea782ccfb2e277d"><td class="mdescLeft">&#160;</td><td class="mdescRight">Pointwise addition operation.  <a href="group__group__nn__kernel__functions.html#ga1a1c20d1fd2b23d54ea782ccfb2e277d">More...</a><br /></td></tr>
<tr class="separator:ga1a1c20d1fd2b23d54ea782ccfb2e277d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga162d327e497e433aa38c1eff3adce291"><td class="memItemLeft" align="right" valign="top"><a class="el" href="group__group__nnlite__enums.html#ga8714c4a5105d4130fb67c76b0d9a1920">cy_en_nnlite_status_t</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group__group__nn__kernel__functions.html#ga162d327e497e433aa38c1eff3adce291">Cy_NNLite_AddDMA</a> (const int8_t *lhsData, const int8_t *rhsData, int8_t *outData, const <a class="el" href="group__group__nn__kernel__data__structures.html#structcy__nn__dims__t">cy_nn_dims_t</a> *lhsDims, const <a class="el" href="group__group__nn__kernel__data__structures.html#structcy__nn__dims__t">cy_nn_dims_t</a> *rhsOutDims, const <a class="el" href="group__group__nn__kernel__data__structures.html#structcy__nn__pwise__binary__params__t">cy_nn_pwise_binary_params_t</a> *pwParams)</td></tr>
<tr class="memdesc:ga162d327e497e433aa38c1eff3adce291"><td class="mdescLeft">&#160;</td><td class="mdescRight">Pointwise addition operation.  <a href="group__group__nn__kernel__functions.html#ga162d327e497e433aa38c1eff3adce291">More...</a><br /></td></tr>
<tr class="separator:ga162d327e497e433aa38c1eff3adce291"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga0710ea5b33d8520b6f3eba69c90e3516"><td class="memItemLeft" align="right" valign="top"><a class="el" href="group__group__nnlite__enums.html#ga8714c4a5105d4130fb67c76b0d9a1920">cy_en_nnlite_status_t</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group__group__nn__kernel__functions.html#ga0710ea5b33d8520b6f3eba69c90e3516">Cy_NNLite_Sub</a> (const int8_t *lhsData, const int8_t *rhsData, int8_t *outData, const <a class="el" href="group__group__nn__kernel__data__structures.html#structcy__nn__dims__t">cy_nn_dims_t</a> *lhsDims, const <a class="el" href="group__group__nn__kernel__data__structures.html#structcy__nn__dims__t">cy_nn_dims_t</a> *rhsOutDims, const <a class="el" href="group__group__nn__kernel__data__structures.html#structcy__nn__pwise__binary__params__t">cy_nn_pwise_binary_params_t</a> *pwParams, bool left_from_right)</td></tr>
<tr class="memdesc:ga0710ea5b33d8520b6f3eba69c90e3516"><td class="mdescLeft">&#160;</td><td class="mdescRight">Pointwise addition operation.  <a href="group__group__nn__kernel__functions.html#ga0710ea5b33d8520b6f3eba69c90e3516">More...</a><br /></td></tr>
<tr class="separator:ga0710ea5b33d8520b6f3eba69c90e3516"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga8ed2232c6d1557f3e7d0450cb5c7d516"><td class="memItemLeft" align="right" valign="top"><a class="el" href="group__group__nnlite__enums.html#ga8714c4a5105d4130fb67c76b0d9a1920">cy_en_nnlite_status_t</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group__group__nn__kernel__functions.html#ga8ed2232c6d1557f3e7d0450cb5c7d516">Cy_NNLite_SubDMA</a> (const int8_t *lhsData, const int8_t *rhsData, int8_t *outData, const <a class="el" href="group__group__nn__kernel__data__structures.html#structcy__nn__dims__t">cy_nn_dims_t</a> *lhsDims, const <a class="el" href="group__group__nn__kernel__data__structures.html#structcy__nn__dims__t">cy_nn_dims_t</a> *rhsOutDims, const <a class="el" href="group__group__nn__kernel__data__structures.html#structcy__nn__pwise__binary__params__t">cy_nn_pwise_binary_params_t</a> *pwParams, bool left_from_right)</td></tr>
<tr class="memdesc:ga8ed2232c6d1557f3e7d0450cb5c7d516"><td class="mdescLeft">&#160;</td><td class="mdescRight">Pointwise addition operation.  <a href="group__group__nn__kernel__functions.html#ga8ed2232c6d1557f3e7d0450cb5c7d516">More...</a><br /></td></tr>
<tr class="separator:ga8ed2232c6d1557f3e7d0450cb5c7d516"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga37d624dd67d791c09e958fb90b68f374"><td class="memItemLeft" align="right" valign="top"><a class="el" href="group__group__nnlite__enums.html#ga8714c4a5105d4130fb67c76b0d9a1920">cy_en_nnlite_status_t</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group__group__nn__kernel__functions.html#ga37d624dd67d791c09e958fb90b68f374">Cy_NNLite_Mul</a> (const int8_t *lhsData, const int8_t *rhsData, int8_t *outData, const <a class="el" href="group__group__nn__kernel__data__structures.html#structcy__nn__dims__t">cy_nn_dims_t</a> *lhsDims, const <a class="el" href="group__group__nn__kernel__data__structures.html#structcy__nn__dims__t">cy_nn_dims_t</a> *rhsOutDims, const <a class="el" href="group__group__nn__kernel__data__structures.html#structcy__nn__pwise__binary__params__t">cy_nn_pwise_binary_params_t</a> *pwParams)</td></tr>
<tr class="memdesc:ga37d624dd67d791c09e958fb90b68f374"><td class="mdescLeft">&#160;</td><td class="mdescRight">multiplication  <a href="group__group__nn__kernel__functions.html#ga37d624dd67d791c09e958fb90b68f374">More...</a><br /></td></tr>
<tr class="separator:ga37d624dd67d791c09e958fb90b68f374"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga754ee6761941470c18af83f1310758f5"><td class="memItemLeft" align="right" valign="top"><a class="el" href="group__group__nnlite__enums.html#ga8714c4a5105d4130fb67c76b0d9a1920">cy_en_nnlite_status_t</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group__group__nn__kernel__functions.html#ga754ee6761941470c18af83f1310758f5">Cy_NNLite_MulDMA</a> (const int8_t *lhsData, const int8_t *rhsData, int8_t *outData, const <a class="el" href="group__group__nn__kernel__data__structures.html#structcy__nn__dims__t">cy_nn_dims_t</a> *lhsDims, const <a class="el" href="group__group__nn__kernel__data__structures.html#structcy__nn__dims__t">cy_nn_dims_t</a> *rhsOutDims, const <a class="el" href="group__group__nn__kernel__data__structures.html#structcy__nn__pwise__binary__params__t">cy_nn_pwise_binary_params_t</a> *pwParams)</td></tr>
<tr class="memdesc:ga754ee6761941470c18af83f1310758f5"><td class="mdescLeft">&#160;</td><td class="mdescRight">Pointwise multiplication with simple broadcast.  <a href="group__group__nn__kernel__functions.html#ga754ee6761941470c18af83f1310758f5">More...</a><br /></td></tr>
<tr class="separator:ga754ee6761941470c18af83f1310758f5"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga275a1c8f56cf804ffb6443bd68686868"><td class="memItemLeft" align="right" valign="top"><a class="el" href="group__group__nnlite__enums.html#ga8714c4a5105d4130fb67c76b0d9a1920">cy_en_nnlite_status_t</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group__group__nn__kernel__functions.html#ga275a1c8f56cf804ffb6443bd68686868">Cy_NNLite_Activation</a> (const int8_t *inData, int8_t *outData, const <a class="el" href="group__group__nn__kernel__data__structures.html#structcy__nn__dims__t">cy_nn_dims_t</a> *inoutDims, const <a class="el" href="group__group__nn__kernel__data__structures.html#structcy__nn__pwise__unary__params__t">cy_nn_pwise_unary_params_t</a> *actParams, <a class="el" href="group__group__nnlite__enums.html#ga384cb7d2feea111076bbd75ae43e60f6">cy_en_nnlite_fused_activation_t</a> act_type, <a class="el" href="group__group__nn__kernel__data__structures.html#structcy__nn__act__intrpl__param__t">cy_nn_act_intrpl_param_t</a> *intrplParam)</td></tr>
<tr class="memdesc:ga275a1c8f56cf804ffb6443bd68686868"><td class="mdescLeft">&#160;</td><td class="mdescRight">Unfused Activation function CPU mode kernel API, API will configure nnlite and then start nnlite operation.  <a href="group__group__nn__kernel__functions.html#ga275a1c8f56cf804ffb6443bd68686868">More...</a><br /></td></tr>
<tr class="separator:ga275a1c8f56cf804ffb6443bd68686868"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:gab3331f4c70fb2fd0263ae5a13313fa6d"><td class="memItemLeft" align="right" valign="top"><a class="el" href="group__group__nnlite__enums.html#ga8714c4a5105d4130fb67c76b0d9a1920">cy_en_nnlite_status_t</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group__group__nn__kernel__functions.html#gab3331f4c70fb2fd0263ae5a13313fa6d">Cy_NNLite_ActivationDMA</a> (const int8_t *inData, int8_t *outData, const <a class="el" href="group__group__nn__kernel__data__structures.html#structcy__nn__dims__t">cy_nn_dims_t</a> *inoutDims, const <a class="el" href="group__group__nn__kernel__data__structures.html#structcy__nn__pwise__unary__params__t">cy_nn_pwise_unary_params_t</a> *actParams, <a class="el" href="group__group__nnlite__enums.html#ga384cb7d2feea111076bbd75ae43e60f6">cy_en_nnlite_fused_activation_t</a> act_type, <a class="el" href="group__group__nn__kernel__data__structures.html#structcy__nn__act__intrpl__param__t">cy_nn_act_intrpl_param_t</a> *intrplParam)</td></tr>
<tr class="memdesc:gab3331f4c70fb2fd0263ae5a13313fa6d"><td class="mdescLeft">&#160;</td><td class="mdescRight">Unfused Activation function DMA mode kernel API,API will configure DMA descriptor pointing nnlite MEMIO configuration structure.  <a href="group__group__nn__kernel__functions.html#gab3331f4c70fb2fd0263ae5a13313fa6d">More...</a><br /></td></tr>
<tr class="separator:gab3331f4c70fb2fd0263ae5a13313fa6d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga2c0e42bffa7ef0bdee32c41029c1795f"><td class="memItemLeft" align="right" valign="top"><a class="el" href="group__group__nnlite__enums.html#ga8714c4a5105d4130fb67c76b0d9a1920">cy_en_nnlite_status_t</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group__group__nn__kernel__functions.html#ga2c0e42bffa7ef0bdee32c41029c1795f">Cy_NNLite_LayerNorm</a> (const int8_t *inputData, int8_t *outputData, const <a class="el" href="group__group__nn__kernel__data__structures.html#structcy__nn__dims__t">cy_nn_dims_t</a> *inputDims, const <a class="el" href="group__group__nn__kernel__data__structures.html#structcy__nn__dims__t">cy_nn_dims_t</a> *outputDims, const <a class="el" href="group__group__nn__kernel__data__structures.html#structcy__nn__layernorm__params__t">cy_nn_layernorm_params_t</a> *lnParams)</td></tr>
<tr class="memdesc:ga2c0e42bffa7ef0bdee32c41029c1795f"><td class="mdescLeft">&#160;</td><td class="mdescRight">Compute composite LayerNorm operation.  <a href="group__group__nn__kernel__functions.html#ga2c0e42bffa7ef0bdee32c41029c1795f">More...</a><br /></td></tr>
<tr class="separator:ga2c0e42bffa7ef0bdee32c41029c1795f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:gad1ce670783c5243e247954eb26f7d1b0"><td class="memItemLeft" align="right" valign="top"><a id="gad1ce670783c5243e247954eb26f7d1b0" name="gad1ce670783c5243e247954eb26f7d1b0"></a>
uint32_t&#160;</td><td class="memItemRight" valign="bottom"><b>Cy_NNLite_LayerNormScratchBufSize</b> (const <a class="el" href="group__group__nn__kernel__data__structures.html#structcy__nn__dims__t">cy_nn_dims_t</a> *inputDims, <a class="el" href="group__group__nnlite__enums.html#gab1d317e2be183e109725321de8c31bdb">cy_en_nnlite_activation_size_t</a> inputSize)</td></tr>
<tr class="memdesc:gad1ce670783c5243e247954eb26f7d1b0"><td class="mdescLeft">&#160;</td><td class="mdescRight">API will return scratch buffer size for LayerNorm kernel, buffer will be used for intermediate calculations. <br /></td></tr>
<tr class="separator:gad1ce670783c5243e247954eb26f7d1b0"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga39fe05b891ec370a3c80098fc0c226ec"><td class="memItemLeft" align="right" valign="top"><a class="el" href="group__group__nnlite__enums.html#ga8714c4a5105d4130fb67c76b0d9a1920">cy_en_nnlite_status_t</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group__group__nn__kernel__functions.html#ga39fe05b891ec370a3c80098fc0c226ec">Cy_NNLite_Byte_Copy</a> (const int8_t *inData, int8_t *outData, uint32_t count)</td></tr>
<tr class="memdesc:ga39fe05b891ec370a3c80098fc0c226ec"><td class="mdescLeft">&#160;</td><td class="mdescRight">Byte block copy using NNLite.  <a href="group__group__nn__kernel__functions.html#ga39fe05b891ec370a3c80098fc0c226ec">More...</a><br /></td></tr>
<tr class="separator:ga39fe05b891ec370a3c80098fc0c226ec"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga8f9de2b7fd88bf1cf4a5d312e5d629b5"><td class="memItemLeft" align="right" valign="top"><a class="el" href="group__group__nnlite__enums.html#ga8714c4a5105d4130fb67c76b0d9a1920">cy_en_nnlite_status_t</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group__group__nn__kernel__functions.html#ga8f9de2b7fd88bf1cf4a5d312e5d629b5">Cy_NNLite_Q31Reciprocal</a> (const uint32_t *inData, float *outData, const <a class="el" href="group__group__nn__kernel__data__structures.html#structcy__nn__dims__t">cy_nn_dims_t</a> *inoutDims)</td></tr>
<tr class="memdesc:ga8f9de2b7fd88bf1cf4a5d312e5d629b5"><td class="mdescLeft">&#160;</td><td class="mdescRight">Float reciprocal of (sums of) unsigned Q.31 values CPU mode kernel API.  <a href="group__group__nn__kernel__functions.html#ga8f9de2b7fd88bf1cf4a5d312e5d629b5">More...</a><br /></td></tr>
<tr class="separator:ga8f9de2b7fd88bf1cf4a5d312e5d629b5"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:gabd5ac089791284c715ad20d82bf66453"><td class="memItemLeft" align="right" valign="top"><a class="el" href="group__group__nnlite__enums.html#ga8714c4a5105d4130fb67c76b0d9a1920">cy_en_nnlite_status_t</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group__group__nn__kernel__functions.html#gabd5ac089791284c715ad20d82bf66453">Cy_NNLite_LSTM_Int8</a> (<a class="el" href="structcy__nn__lstm__context.html">cy_nn_lstm_context</a> *scratch_buffers, const int8_t *input_data, const <a class="el" href="structcy__nn__lstm__dims.html">cy_nn_lstm_dims</a> *lstm_dims, const int8_t *input_to_input_weights, const int8_t *input_to_forget_weights, const int8_t *input_to_cell_weights, const int8_t *input_to_output_weights, const int8_t *recurrent_to_input_weights, const int8_t *recurrent_to_forget_weights, const int8_t *recurrent_to_cell_weights, const int8_t *recurrent_to_output_weights, const int8_t *projection_weights, const <a class="el" href="structcy__nn__lstm__params.html">cy_nn_lstm_params</a> *lstm, int8_t *output_state, int16_t *cell_state, int8_t *output_data)</td></tr>
<tr class="memdesc:gabd5ac089791284c715ad20d82bf66453"><td class="mdescLeft">&#160;</td><td class="mdescRight">LSTM unidirectional function with 8 bit input and output and 16 bit gate output Peephole connections, projection, clipping, combined input/forget gate and layer normalization are not supported.  <a href="group__group__nn__kernel__functions.html#gabd5ac089791284c715ad20d82bf66453">More...</a><br /></td></tr>
<tr class="separator:gabd5ac089791284c715ad20d82bf66453"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:gab3d27f971da724a7522c05ea5e2df014"><td class="memItemLeft" align="right" valign="top">uint32_t&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group__group__nn__kernel__functions.html#gab3d27f971da724a7522c05ea5e2df014">Cy_NNLite_SoftMax_ScratchBufSize</a> (const <a class="el" href="group__group__nn__kernel__data__structures.html#structcy__nn__dims__t">cy_nn_dims_t</a> *inoutDims, const <a class="el" href="group__group__nnlite__enums.html#gab1d317e2be183e109725321de8c31bdb">cy_en_nnlite_activation_size_t</a> act_size)</td></tr>
<tr class="memdesc:gab3d27f971da724a7522c05ea5e2df014"><td class="mdescLeft">&#160;</td><td class="mdescRight">Compute scratch buffer size needed to compute row-wise softmax of 2D input tensor.  <a href="group__group__nn__kernel__functions.html#gab3d27f971da724a7522c05ea5e2df014">More...</a><br /></td></tr>
<tr class="separator:gab3d27f971da724a7522c05ea5e2df014"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:gac54a6093cd8b0163aaaa07846f7b3a5a"><td class="memItemLeft" align="right" valign="top">uint32_t&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group__group__nn__kernel__functions.html#gac54a6093cd8b0163aaaa07846f7b3a5a">Cy_NNLite_FC_ScratchBufSize</a> (const <a class="el" href="group__group__nn__kernel__data__structures.html#structcy__nn__dims__t">cy_nn_dims_t</a> *inDims, const <a class="el" href="group__group__nn__kernel__data__structures.html#structcy__nn__dims__t">cy_nn_dims_t</a> *outDims)</td></tr>
<tr class="memdesc:gac54a6093cd8b0163aaaa07846f7b3a5a"><td class="mdescLeft">&#160;</td><td class="mdescRight">Compute size scratch buffer required for FC op.  <a href="group__group__nn__kernel__functions.html#gac54a6093cd8b0163aaaa07846f7b3a5a">More...</a><br /></td></tr>
<tr class="separator:gac54a6093cd8b0163aaaa07846f7b3a5a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga8a96c7516ac63769ae913faa36a2732b"><td class="memItemLeft" align="right" valign="top">uint32_t&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group__group__nn__kernel__functions.html#ga8a96c7516ac63769ae913faa36a2732b">Cy_NNLite_DMAModeScratchBufSize</a> (void)</td></tr>
<tr class="memdesc:ga8a96c7516ac63769ae913faa36a2732b"><td class="mdescLeft">&#160;</td><td class="mdescRight">Compute scratch buffer size needed for DMA mode API.  <a href="group__group__nn__kernel__functions.html#ga8a96c7516ac63769ae913faa36a2732b">More...</a><br /></td></tr>
<tr class="separator:ga8a96c7516ac63769ae913faa36a2732b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga0f1ab40879e8ec6bf78fac24502e08cb"><td class="memItemLeft" align="right" valign="top"><a class="el" href="group__group__nnlite__enums.html#ga8714c4a5105d4130fb67c76b0d9a1920">cy_en_nnlite_status_t</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group__group__nn__kernel__functions.html#ga0f1ab40879e8ec6bf78fac24502e08cb">Cy_NNLite_TriggerDMAQueue</a> (void)</td></tr>
<tr class="memdesc:ga0f1ab40879e8ec6bf78fac24502e08cb"><td class="mdescLeft">&#160;</td><td class="mdescRight">Cy_NNLite_TriggerDMAQueue will trigger DMA transfer of Queued layer starting from first queued layer, callback function will be called after completion of all the Queued layer if valid callback function is passed in kernel context, API will work in blocking mode if callback function is NULL.  <a href="group__group__nn__kernel__functions.html#ga0f1ab40879e8ec6bf78fac24502e08cb">More...</a><br /></td></tr>
<tr class="separator:ga0f1ab40879e8ec6bf78fac24502e08cb"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga2e7d7281eed1a4a04dc5e7198a286376"><td class="memItemLeft" align="right" valign="top">uint32_t&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group__group__nn__kernel__functions.html#ga2e7d7281eed1a4a04dc5e7198a286376">Cy_NNLite_GetQueuedLayerCount</a> (void)</td></tr>
<tr class="memdesc:ga2e7d7281eed1a4a04dc5e7198a286376"><td class="mdescLeft">&#160;</td><td class="mdescRight">Cy_NNLite_GetQueuedLayerCount will return count of queued layer for DMA.  <a href="group__group__nn__kernel__functions.html#ga2e7d7281eed1a4a04dc5e7198a286376">More...</a><br /></td></tr>
<tr class="separator:ga2e7d7281eed1a4a04dc5e7198a286376"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga30aabc8d3c9ac00f08c73b3ad51c2f92"><td class="memItemLeft" align="right" valign="top"><a class="el" href="group__group__nnlite__enums.html#ga8714c4a5105d4130fb67c76b0d9a1920">cy_en_nnlite_status_t</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group__group__nn__kernel__functions.html#ga30aabc8d3c9ac00f08c73b3ad51c2f92">Cy_NNLite_GetCurrDMAQueue</a> (<a class="el" href="group__group__nn__kernel__data__structures.html#structcy__nnlite__dma__queue__config__t">cy_nnlite_dma_queue_config_t</a> *dmaQueue)</td></tr>
<tr class="memdesc:ga30aabc8d3c9ac00f08c73b3ad51c2f92"><td class="mdescLeft">&#160;</td><td class="mdescRight">Cy_NNLite_GetCurrDMAQueue API will copy current dma queue in to dmaQueue pointer, valid dmaQueue pointer should be passed.  <a href="group__group__nn__kernel__functions.html#ga30aabc8d3c9ac00f08c73b3ad51c2f92">More...</a><br /></td></tr>
<tr class="separator:ga30aabc8d3c9ac00f08c73b3ad51c2f92"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:gaecab45a2c729ad12523ad57066f413f3"><td class="memItemLeft" align="right" valign="top"><a class="el" href="group__group__nnlite__enums.html#ga8714c4a5105d4130fb67c76b0d9a1920">cy_en_nnlite_status_t</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group__group__nn__kernel__functions.html#gaecab45a2c729ad12523ad57066f413f3">Cy_NNLite_RunDMAQueue</a> (<a class="el" href="group__group__nn__kernel__data__structures.html#structcy__nnlite__dma__queue__config__t">cy_nnlite_dma_queue_config_t</a> *dmaQueue)</td></tr>
<tr class="memdesc:gaecab45a2c729ad12523ad57066f413f3"><td class="mdescLeft">&#160;</td><td class="mdescRight">Cy_NNLite_RunDMAQueue API will Trigger DMA dmaQueue queue valid dmaQueue pointer should be passed, DMA queue should return from Cy_NNLite_GetCurrDMAQueue queue will be in runnable state if Cy_NNLite_GetCurrDMAQueue called after queue created in Kernel DMA API such as Cy_NNLite_AvgpoolDMA and get executed by calling Cy_NNLite_TriggerDMAQueue.  <a href="group__group__nn__kernel__functions.html#gaecab45a2c729ad12523ad57066f413f3">More...</a><br /></td></tr>
<tr class="separator:gaecab45a2c729ad12523ad57066f413f3"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:gafe4dcd66f1780509daf8dc2a4657622e"><td class="memItemLeft" align="right" valign="top"><a class="el" href="group__group__nnlite__enums.html#ga8714c4a5105d4130fb67c76b0d9a1920">cy_en_nnlite_status_t</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group__group__nn__kernel__functions.html#gafe4dcd66f1780509daf8dc2a4657622e">Cy_NNLite_SoftMax</a> (const int8_t *inData, int8_t *outData, int8_t *expTempBuf, const <a class="el" href="group__group__nn__kernel__data__structures.html#structcy__nn__dims__t">cy_nn_dims_t</a> *inoutDims, const <a class="el" href="group__group__nn__kernel__data__structures.html#structcy__nn__pwise__unary__params__t">cy_nn_pwise_unary_params_t</a> *smParams)</td></tr>
<tr class="memdesc:gafe4dcd66f1780509daf8dc2a4657622e"><td class="mdescLeft">&#160;</td><td class="mdescRight">Compute row-wise softmax of 2D input tensor.  <a href="group__group__nn__kernel__functions.html#gafe4dcd66f1780509daf8dc2a4657622e">More...</a><br /></td></tr>
<tr class="separator:gafe4dcd66f1780509daf8dc2a4657622e"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga98348ccbe6152350b2991171ad1b92c0"><td class="memItemLeft" align="right" valign="top"><a class="el" href="group__group__nnlite__enums.html#ga8714c4a5105d4130fb67c76b0d9a1920">cy_en_nnlite_status_t</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group__group__nn__kernel__functions.html#ga98348ccbe6152350b2991171ad1b92c0">Cy_NNLite_FFT</a> (int32_t *ppBuf0, int32_t *ppBuf1, unsigned int fftStages)</td></tr>
<tr class="memdesc:ga98348ccbe6152350b2991171ad1b92c0"><td class="mdescLeft">&#160;</td><td class="mdescRight">Compute Q1.15 complex FFT.  <a href="group__group__nn__kernel__functions.html#ga98348ccbe6152350b2991171ad1b92c0">More...</a><br /></td></tr>
<tr class="separator:ga98348ccbe6152350b2991171ad1b92c0"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:gad35f48e879493c686af5e10c956c8901"><td class="memItemLeft" align="right" valign="top"><a class="el" href="group__group__nnlite__enums.html#ga8714c4a5105d4130fb67c76b0d9a1920">cy_en_nnlite_status_t</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group__group__nn__kernel__functions.html#gad35f48e879493c686af5e10c956c8901">Cy_NNLite_FFTDMA</a> (int32_t *ppBuf0, int32_t *ppBuf1, unsigned int fftStages, void *scratchBuf)</td></tr>
<tr class="memdesc:gad35f48e879493c686af5e10c956c8901"><td class="mdescLeft">&#160;</td><td class="mdescRight">Compute Q1.15 complex FFT DMA mode API API will configure DMA descriptor pointing nnlite MEMIO configuration structure.  <a href="group__group__nn__kernel__functions.html#gad35f48e879493c686af5e10c956c8901">More...</a><br /></td></tr>
<tr class="separator:gad35f48e879493c686af5e10c956c8901"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga80cc663bc1668fe1a9167335e8985173"><td class="memItemLeft" align="right" valign="top"><a class="el" href="group__group__nnlite__enums.html#ga8714c4a5105d4130fb67c76b0d9a1920">cy_en_nnlite_status_t</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group__group__nn__kernel__functions.html#ga80cc663bc1668fe1a9167335e8985173">Cy_NNLite_KernelInit</a> (<a class="el" href="group__group__nn__kernel__data__structures.html#structcy__kernel__config__t">cy_kernel_config_t</a> *kernelConfig)</td></tr>
<tr class="memdesc:ga80cc663bc1668fe1a9167335e8985173"><td class="mdescLeft">&#160;</td><td class="mdescRight">Kernel Init API, initialize PDL driver and setup IRQ handler, setup function pointers from kernelConfig argument.  <a href="group__group__nn__kernel__functions.html#ga80cc663bc1668fe1a9167335e8985173">More...</a><br /></td></tr>
<tr class="separator:ga80cc663bc1668fe1a9167335e8985173"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:gaf938f97f72466428554fe4694cc25722"><td class="memItemLeft" align="right" valign="top"><a class="el" href="group__group__nnlite__enums.html#ga8714c4a5105d4130fb67c76b0d9a1920">cy_en_nnlite_status_t</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group__group__nn__kernel__functions.html#gaf938f97f72466428554fe4694cc25722">Cy_NNLite_KernelDeInit</a> (void)</td></tr>
<tr class="memdesc:gaf938f97f72466428554fe4694cc25722"><td class="mdescLeft">&#160;</td><td class="mdescRight">Kernel Deinit API, de-initialize PDL driver and synchronization primitives.  <a href="group__group__nn__kernel__functions.html#gaf938f97f72466428554fe4694cc25722">More...</a><br /></td></tr>
<tr class="separator:gaf938f97f72466428554fe4694cc25722"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table>
<h2 class="groupheader">Function Documentation</h2>
<a id="gaaf6614a4ce7494a3107cb1163b297953" name="gaaf6614a4ce7494a3107cb1163b297953"></a>
<h2 class="memtitle"><span class="permalink"><a href="#gaaf6614a4ce7494a3107cb1163b297953">&#9670;&nbsp;</a></span>Cy_NNLite_LeakyRelUPWLActivation()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void Cy_NNLite_LeakyRelUPWLActivation </td>
          <td>(</td>
          <td class="paramtype">float&#160;</td>
          <td class="paramname"><em>alpha_scale</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">float&#160;</td>
          <td class="paramname"><em>unit_scale</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="group__group__nn__kernel__data__structures.html#structcy__nn__act__intrpl__param__t">cy_nn_act_intrpl_param_t</a> *&#160;</td>
          <td class="paramname"><em>leakyRelU</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Set PWL interpolation parameters for LeakyRElU activation. </p>
<p >[in] alpha_scale LeakyRelU scale for alpha parameter (may fold in a rescaling factor) [in] unit_scale LeakyRelU scale for unit gradient (may fold in a rescaling factor) [in] inParam Pointer to PWL activation struct to set for specified <code>alpha</code> </p>

</div>
</div>
<a id="ga61dad25009def8305d3c1158aca22656" name="ga61dad25009def8305d3c1158aca22656"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ga61dad25009def8305d3c1158aca22656">&#9670;&nbsp;</a></span>Cy_NNLite_Convolution()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="group__group__nnlite__enums.html#ga8714c4a5105d4130fb67c76b0d9a1920">cy_en_nnlite_status_t</a> Cy_NNLite_Convolution </td>
          <td>(</td>
          <td class="paramtype">const int8_t *&#160;</td>
          <td class="paramname"><em>inputData</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int8_t *&#160;</td>
          <td class="paramname"><em>outData</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="group__group__nn__kernel__data__structures.html#structcy__nn__dims__t">cy_nn_dims_t</a> *&#160;</td>
          <td class="paramname"><em>inputDims</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="group__group__nn__kernel__data__structures.html#structcy__nn__dims__t">cy_nn_dims_t</a> *&#160;</td>
          <td class="paramname"><em>outputDims</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="group__group__nn__kernel__data__structures.html#structcy__nn__dims__t">cy_nn_dims_t</a> *&#160;</td>
          <td class="paramname"><em>filterDims</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int8_t *&#160;</td>
          <td class="paramname"><em>filterData</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int32_t *&#160;</td>
          <td class="paramname"><em>biasData</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="group__group__nn__kernel__data__structures.html#structcy__nn__conv__params__t">cy_nn_conv_params_t</a> *&#160;</td>
          <td class="paramname"><em>convParam</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="group__group__nnlite__enums.html#ga384cb7d2feea111076bbd75ae43e60f6">cy_en_nnlite_fused_activation_t</a>&#160;</td>
          <td class="paramname"><em>actType</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="group__group__nn__kernel__data__structures.html#structcy__nn__act__intrpl__param__t">cy_nn_act_intrpl_param_t</a> *&#160;</td>
          <td class="paramname"><em>intrplParam</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>2D Convolution CPU mode kernel API, API will configure nnlite and then start nnlite operation.API will work in blocking mode if callback function in Kernel config structure is NULL, if valid callback function is passed in Kernel config, API will be non-blocking and callback function will be called after completion of layer, caller need to wait for callback function before calling another Kernel API, else error will be for other function </p>
<p >filterData points to weights if sparse weight or non sparse based base on type of packing is used</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">inputData</td><td>activation buffer pointer</td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">outData</td><td>output buffer pointer</td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">inputDims</td><td>activation dimension pointer</td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">outputDims</td><td>output dimension pointer</td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">filterDims</td><td>filter dimension pointer</td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">filterData</td><td>filter pointer</td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">biasData</td><td>bias pointer</td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">convParam</td><td>convolution parameter structure pointer</td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">actType</td><td>output activation type</td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">intrplParam</td><td>interpolation param for PWL <code>actType</code> output activation</td></tr>
  </table>
  </dd>
</dl>
<dl class="retval"><dt>Return values</dt><dd>
  <table class="retval">
    <tr><td class="paramname">Refer</td><td><a class="el" href="group__group__nnlite__enums.html#ga8714c4a5105d4130fb67c76b0d9a1920">cy_en_nnlite_status_t</a></td></tr>
  </table>
  </dd>
</dl>
<p>2D Convolution CPU mode kernel API, API will configure nnlite and then start nnlite operation.API will work in blocking mode if callback function in Kernel config structure is NULL, if valid callback function is passed in Kernel config, API will be non-blocking and callback function will be called after completion of layer, caller need to wait for callback function before calling another Kernel API, else error will be for other function</p>
<p >Kernel config structure should point to valid callback function. filterData points to weights if sparsityBaseAddr is NULL otherwise weights pointer will be derived from sparsityBaseAddr and filterData will not be used. Valid scratch buffer should be passed in convParam, scratch buffer will be used for transpose operation (transpose scratch buffer and transpose DMA descriptors)for per axis convolution implementation, size of scratch buffer should be derived by calling function Cy_NNLite_ConvolutionScratchBufSize. Scratch buffer can be freed after receiving completion callback of API.</p>
<p >[in] inputData activation buffer pointer</p>
<p >[in] outData output buffer pointer</p>
<p >[in] inputDims activation dimension pointer</p>
<p >[in] outpututDims output dimension pointer</p>
<p >[in] filterDims filter dimension pointer</p>
<p >[in] filterData filter pointer</p>
<p >[in] biasData bias pointer</p>
<p >[in] sparsityBaseAddr sparsity map base pointer</p>
<p >[in] convParam convolution parameter structure pointer</p>
<p >[in] actType output activation type</p>
<p >[in] intrplParam interpolation param for PWL output activation, null = nothing set </p>

</div>
</div>
<a id="ga6c81f67a76e5ba45c648a9538fb988cb" name="ga6c81f67a76e5ba45c648a9538fb988cb"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ga6c81f67a76e5ba45c648a9538fb988cb">&#9670;&nbsp;</a></span>Cy_NNLite_ConvolutionDMA()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="group__group__nnlite__enums.html#ga8714c4a5105d4130fb67c76b0d9a1920">cy_en_nnlite_status_t</a> Cy_NNLite_ConvolutionDMA </td>
          <td>(</td>
          <td class="paramtype">const int8_t *&#160;</td>
          <td class="paramname"><em>inputData</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int8_t *&#160;</td>
          <td class="paramname"><em>outData</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="group__group__nn__kernel__data__structures.html#structcy__nn__dims__t">cy_nn_dims_t</a> *&#160;</td>
          <td class="paramname"><em>inputDims</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="group__group__nn__kernel__data__structures.html#structcy__nn__dims__t">cy_nn_dims_t</a> *&#160;</td>
          <td class="paramname"><em>outputDims</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="group__group__nn__kernel__data__structures.html#structcy__nn__dims__t">cy_nn_dims_t</a> *&#160;</td>
          <td class="paramname"><em>filterDims</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int8_t *&#160;</td>
          <td class="paramname"><em>filterData</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int32_t *&#160;</td>
          <td class="paramname"><em>biasData</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="group__group__nn__kernel__data__structures.html#structcy__nn__conv__params__t">cy_nn_conv_params_t</a> *&#160;</td>
          <td class="paramname"><em>convParam</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="group__group__nnlite__enums.html#ga384cb7d2feea111076bbd75ae43e60f6">cy_en_nnlite_fused_activation_t</a>&#160;</td>
          <td class="paramname"><em>actType</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="group__group__nn__kernel__data__structures.html#structcy__nn__act__intrpl__param__t">cy_nn_act_intrpl_param_t</a> *&#160;</td>
          <td class="paramname"><em>intrplParam</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>2D Convolution DMA mode kernel API, API will configure DMA descriptor pointing nnlite MEMIO configuration structure. </p>
<p >Valid scratch buffer should be passed in convParam, scratch buffer will be used for nnlite MEMIO configuration structure, size of scratch buffer should be value return from Cy_NNLite_ScratchBufSize. CY_NNLITE_OP_QUEUED will be the return value on success After queuing kernel, DMA needs to be triggered by calling API Cy_TriggerNNLiteDMAQueue</p>
<p >filterData points to weights if sparse weight or non sparse based base on type of packing is used</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">inputData</td><td>activation buffer pointer</td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">outData</td><td>output buffer pointer</td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">inputDims</td><td>activation dimension pointer</td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">outputDims</td><td>output dimension pointer</td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">filterDims</td><td>filter dimension pointer</td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">filterData</td><td>filter pointer</td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">biasData</td><td>bias pointer</td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">convParam</td><td>convolution parameter structure pointer</td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">actType</td><td>output activation type</td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">intrplParam</td><td>interpolation param for PWL <code>actType</code> output activation</td></tr>
  </table>
  </dd>
</dl>
<dl class="retval"><dt>Return values</dt><dd>
  <table class="retval">
    <tr><td class="paramname">Refer</td><td><a class="el" href="group__group__nnlite__enums.html#ga8714c4a5105d4130fb67c76b0d9a1920">cy_en_nnlite_status_t</a> </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="gaa801087a50601af4eb3c57a0e5065ed0" name="gaa801087a50601af4eb3c57a0e5065ed0"></a>
<h2 class="memtitle"><span class="permalink"><a href="#gaa801087a50601af4eb3c57a0e5065ed0">&#9670;&nbsp;</a></span>Cy_NNLite_DepthwiseConvolution()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="group__group__nnlite__enums.html#ga8714c4a5105d4130fb67c76b0d9a1920">cy_en_nnlite_status_t</a> Cy_NNLite_DepthwiseConvolution </td>
          <td>(</td>
          <td class="paramtype">const int8_t *&#160;</td>
          <td class="paramname"><em>inputData</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int8_t *&#160;</td>
          <td class="paramname"><em>outData</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="group__group__nn__kernel__data__structures.html#structcy__nn__dims__t">cy_nn_dims_t</a> *&#160;</td>
          <td class="paramname"><em>inputDims</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="group__group__nn__kernel__data__structures.html#structcy__nn__dims__t">cy_nn_dims_t</a> *&#160;</td>
          <td class="paramname"><em>outputDims</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="group__group__nn__kernel__data__structures.html#structcy__nn__dims__t">cy_nn_dims_t</a> *&#160;</td>
          <td class="paramname"><em>filterDims</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int8_t *&#160;</td>
          <td class="paramname"><em>filterData</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int32_t *&#160;</td>
          <td class="paramname"><em>biasData</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="group__group__nn__kernel__data__structures.html#structcy__nn__conv__params__t">cy_nn_conv_params_t</a> *&#160;</td>
          <td class="paramname"><em>convParam</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="group__group__nnlite__enums.html#ga384cb7d2feea111076bbd75ae43e60f6">cy_en_nnlite_fused_activation_t</a>&#160;</td>
          <td class="paramname"><em>actType</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="group__group__nn__kernel__data__structures.html#structcy__nn__act__intrpl__param__t">cy_nn_act_intrpl_param_t</a> *&#160;</td>
          <td class="paramname"><em>intrplParam</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Depthwise Convolution CPU mode kernel API, API will work in blocking mode if callback function in Kernel config structure is NULL, if valid callback function is passed in Kernel config, API will be non-blocking and callback function will be called after completion of layer, caller need to wait for callback function before calling another Kernel API, else error will be for other function. </p>
<p >depth multiplier considers as additional stacked channels rather than separate filter channel = input_channel * depth. </p><dl class="section note"><dt>Note</dt><dd>sparse weight data is not supported in depth-wise convolution operation instead of normal “NHWC” special layout is used for depth-wise the layout depends on the number of weights being processed in parallel 'P' (depthMultiplier) P maximum is 4.<ul>
<li>Bias buffer should be always 128 bit aligned, i.e. for 8-bit activations bias buffer should be allocated in multiple of 4 32 bit words and for 16-bit activations bias buffer should be allocated in mutiple of 2 64 bit words.</li>
<li>layout format will be **[N/P]×H×W×P weights for the complete P-weight “stripes” weights, followed by 1×H×W×|N|p array of weights for a final partial stripe &lt; P weights (empty if |N|p≠0 ) P maximum is 4 (2 for 16-bit activations), activation unit first fetches all activations for the sums-of-products for the first 4 (2 for 16 bit)filters then the activations, for the next 4 (2) and so on. Below mention picture show layout for 16 bit activations <div class="image">
<img src="depthwise_kernel_memory_layout.png" alt=""/>
</div>
</li>
</ul>
</dd></dl>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">inputData</td><td>activation buffer pointer</td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">outData</td><td>output buffer pointer</td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">inputDims</td><td>activation dimension pointer</td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">outputDims</td><td>output dimension pointer</td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">filterDims</td><td>filter dimension pointer</td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">filterData</td><td>filter pointer</td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">biasData</td><td>bias pointer</td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">convParam</td><td>convolution parameter structure pointer</td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">actType</td><td>output activation type</td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">intrplParam</td><td>interpolation param for PWL <code>actType</code> activation</td></tr>
  </table>
  </dd>
</dl>
<dl class="retval"><dt>Return values</dt><dd>
  <table class="retval">
    <tr><td class="paramname">Refer</td><td><a class="el" href="group__group__nnlite__enums.html#ga8714c4a5105d4130fb67c76b0d9a1920">cy_en_nnlite_status_t</a> </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="ga2f4ffd40f54b17d26a70975ce828a199" name="ga2f4ffd40f54b17d26a70975ce828a199"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ga2f4ffd40f54b17d26a70975ce828a199">&#9670;&nbsp;</a></span>Cy_NNLite_DepthwiseConvolutionDMA()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="group__group__nnlite__enums.html#ga8714c4a5105d4130fb67c76b0d9a1920">cy_en_nnlite_status_t</a> Cy_NNLite_DepthwiseConvolutionDMA </td>
          <td>(</td>
          <td class="paramtype">const int8_t *&#160;</td>
          <td class="paramname"><em>inputData</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int8_t *&#160;</td>
          <td class="paramname"><em>outData</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="group__group__nn__kernel__data__structures.html#structcy__nn__dims__t">cy_nn_dims_t</a> *&#160;</td>
          <td class="paramname"><em>inputDims</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="group__group__nn__kernel__data__structures.html#structcy__nn__dims__t">cy_nn_dims_t</a> *&#160;</td>
          <td class="paramname"><em>outputDims</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="group__group__nn__kernel__data__structures.html#structcy__nn__dims__t">cy_nn_dims_t</a> *&#160;</td>
          <td class="paramname"><em>filterDims</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int8_t *&#160;</td>
          <td class="paramname"><em>filterData</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int32_t *&#160;</td>
          <td class="paramname"><em>biasData</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="group__group__nn__kernel__data__structures.html#structcy__nn__conv__params__t">cy_nn_conv_params_t</a> *&#160;</td>
          <td class="paramname"><em>convParam</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="group__group__nnlite__enums.html#ga384cb7d2feea111076bbd75ae43e60f6">cy_en_nnlite_fused_activation_t</a>&#160;</td>
          <td class="paramname"><em>actType</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="group__group__nn__kernel__data__structures.html#structcy__nn__act__intrpl__param__t">cy_nn_act_intrpl_param_t</a> *&#160;</td>
          <td class="paramname"><em>intrplParam</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Depthwise DMA mode kernel API, API will configure DMA descriptor pointing nnlite MEMIO configuration structure. </p>
<p >Valid scratch buffer should be passed in convParam, scratch buffer will be used for nnlite MEMIO configuration structure, size of scratch buffer should be value return from Cy_NNLite_ScratchBufSize. CY_NNLITE_OP_QUEUED will be the return value on success After queuing kernel, DMA needs to be triggered by calling API Cy_TriggerNNLiteDMAQueue depth multiplier considers as additional stacked channels rather than separate filter channel = input_channel * depth </p><dl class="section note"><dt>Note</dt><dd>sparse weight data is not supported in depth-wise convolution operation instead of normal “NHWC” special layout is used for depth-wise<ul>
<li>Bias buffer should be always 128 bit aligned, i.e. for 8-bit activations bias buffer should be allocated in multiple of 4 32 bit words and for 16-bit activations bias buffer should be allocated in mutiple of for 2 64 bit words. the layout depends on the number of weights being processed in parallel 'P' (depthMultiplier) layout format will be [N/P]×H×W×P weights for the complete P-weight “stripes” weights, followed by 1×H×W×|N|p array of weights for a final partial stripe &lt; P weights (empty if |N|p≠0 ) P 2-dimensional channel-specific filters in parallel, each called stripe is Pmax 4 for 8 bit activations (2 for 16-bit activations). For each 2D (HW) sampling position the activation unit first fetches all activations for the sums-of-products for the first 4 (2) filters (i.e. the first stripe), then the activations, for the next 4 (2) and so on. Below mentioned picture show layout with 16 bit activations</li>
</ul>
</dd></dl>
<div class="image">
<img src="depthwise_kernel_memory_layout.png" alt=""/>
</div>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">inputData</td><td>activation buffer pointer</td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">outData</td><td>output buffer pointer</td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">inputDims</td><td>activation dimension pointer</td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">outputDims</td><td>output dimension pointer</td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">filterDims</td><td>filter dimension pointer</td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">filterData</td><td>filter pointer</td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">biasData</td><td>bias pointer</td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">convParam</td><td>convolution parameter structure pointer</td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">actType</td><td>output activation type</td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">intrplParam</td><td>interpolation param for PWL <code>actType</code> activation</td></tr>
  </table>
  </dd>
</dl>
<dl class="retval"><dt>Return values</dt><dd>
  <table class="retval">
    <tr><td class="paramname">Refer</td><td><a class="el" href="group__group__nnlite__enums.html#ga8714c4a5105d4130fb67c76b0d9a1920">cy_en_nnlite_status_t</a> </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="gabf4acdda27e317c08d7c11bdb9631e4c" name="gabf4acdda27e317c08d7c11bdb9631e4c"></a>
<h2 class="memtitle"><span class="permalink"><a href="#gabf4acdda27e317c08d7c11bdb9631e4c">&#9670;&nbsp;</a></span>Cy_NNLite_FullyConnected()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="group__group__nnlite__enums.html#ga8714c4a5105d4130fb67c76b0d9a1920">cy_en_nnlite_status_t</a> Cy_NNLite_FullyConnected </td>
          <td>(</td>
          <td class="paramtype">const int8_t *&#160;</td>
          <td class="paramname"><em>inputData</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int8_t *&#160;</td>
          <td class="paramname"><em>outData</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="group__group__nn__kernel__data__structures.html#structcy__nn__dims__t">cy_nn_dims_t</a> *&#160;</td>
          <td class="paramname"><em>inputDims</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="group__group__nn__kernel__data__structures.html#structcy__nn__dims__t">cy_nn_dims_t</a> *&#160;</td>
          <td class="paramname"><em>outputDims</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="group__group__nn__kernel__data__structures.html#structcy__nn__dims__t">cy_nn_dims_t</a> *&#160;</td>
          <td class="paramname"><em>filterDims</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int8_t *&#160;</td>
          <td class="paramname"><em>filterData</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int32_t *&#160;</td>
          <td class="paramname"><em>biasData</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="group__group__nn__kernel__data__structures.html#structcy__nn__fc__params__t">cy_nn_fc_params_t</a> *&#160;</td>
          <td class="paramname"><em>fcParam</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="group__group__nnlite__enums.html#ga384cb7d2feea111076bbd75ae43e60f6">cy_en_nnlite_fused_activation_t</a>&#160;</td>
          <td class="paramname"><em>actType</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="group__group__nn__kernel__data__structures.html#structcy__nn__act__intrpl__param__t">cy_nn_act_intrpl_param_t</a> *&#160;</td>
          <td class="paramname"><em>intrplParam</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Fully connected CPU mode kernel API, API will configure nnlite and then start nnlite operation.API will work in blocking mode For case inputDims-&gt;dims[0] &gt; 1,scratch buffer is required scratch buffer size in CPU should be calculated using Cy_NNLite_FC_ScratchBufSize API if callback function in Kernel config structure is NULL, if valid callback function is passed in Kernel config, API will be non-blocking and callback function will be called after completion of layer, caller need to wait for callback function before calling another Kernel API, else error will be for other function. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">inputData</td><td>activation buffer pointer</td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">outData</td><td>output buffer pointer</td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">inputDims</td><td>activation dimension pointer</td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">outputDims</td><td>output dimension pointer</td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">filterDims</td><td>filter dimension pointer</td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">filterData</td><td>filter data (weights or packed weights structure) pointer</td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">biasData</td><td>bias pointer N.b. 64-bit per value fo r16-bit activations</td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">fcParam</td><td>fully Connected parameter structure pointer</td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">actType</td><td>output activation type</td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">intrplParam</td><td>interpolation param for PWL <code>actType</code> activation</td></tr>
  </table>
  </dd>
</dl>
<dl class="retval"><dt>Return values</dt><dd>
  <table class="retval">
    <tr><td class="paramname">Refer</td><td><a class="el" href="group__group__nnlite__enums.html#ga8714c4a5105d4130fb67c76b0d9a1920">cy_en_nnlite_status_t</a></td></tr>
  </table>
  </dd>
</dl>
<p>Fully connected CPU mode kernel API, API will configure nnlite and then start nnlite operation.API will work in blocking mode For case inputDims-&gt;dims[0] &gt; 1,scratch buffer is required scratch buffer size in CPU should be calculated using Cy_NNLite_FC_ScratchBufSize API if callback function in Kernel config structure is NULL, if valid callback function is passed in Kernel config, API will be non-blocking and callback function will be called after completion of layer, caller need to wait for callback function before calling another Kernel API, else error will be for other function.</p>
<p >Kernel config structure should point to valid callback function. filterData points to weights If sparsityBaseAddr is NULL, otherwise weights pointer will be derived from sparsityBaseAddr and filterData will not be used. For case inputDims-&gt;dims[0] &gt; 1,scratch buffer is required scratch buffer size in CPU should be calculated using Cy_NNLite_FC_ScratchBufSize API For DMA mode scratch is sum of Cy_NNLite_FC_ScratchBufSize &amp; Cy_NNLite_DMAModeScratchBufSize</p>
<p >[in] inputData activation buffer pointer</p>
<p >[in] outData output buffer pointer</p>
<p >[in] inputDims activation dimension pointer</p>
<p >[in] outpututDims output dimension pointer</p>
<p >[in] filterDims filter dimension pointer</p>
<p >[in] filterData filter pointer</p>
<p >[in] biasData bias pointer</p>
<p >[in] sparsityBaseAddr sparsity map base pointer</p>
<p >[in] fcParam fully Connected parameter structure pointer</p>
<p >[in] actType output activation type</p>
<p >[in] intrplParam interpolation param for PWL output activation , null = nothing set </p>

</div>
</div>
<a id="gabdfe1b52e4e3129cd6baa93f81236150" name="gabdfe1b52e4e3129cd6baa93f81236150"></a>
<h2 class="memtitle"><span class="permalink"><a href="#gabdfe1b52e4e3129cd6baa93f81236150">&#9670;&nbsp;</a></span>Cy_NNLite_FullyConnectedDMA()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="group__group__nnlite__enums.html#ga8714c4a5105d4130fb67c76b0d9a1920">cy_en_nnlite_status_t</a> Cy_NNLite_FullyConnectedDMA </td>
          <td>(</td>
          <td class="paramtype">const int8_t *&#160;</td>
          <td class="paramname"><em>inputData</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int8_t *&#160;</td>
          <td class="paramname"><em>outData</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="group__group__nn__kernel__data__structures.html#structcy__nn__dims__t">cy_nn_dims_t</a> *&#160;</td>
          <td class="paramname"><em>inputDims</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="group__group__nn__kernel__data__structures.html#structcy__nn__dims__t">cy_nn_dims_t</a> *&#160;</td>
          <td class="paramname"><em>outputDims</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="group__group__nn__kernel__data__structures.html#structcy__nn__dims__t">cy_nn_dims_t</a> *&#160;</td>
          <td class="paramname"><em>filterDims</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int8_t *&#160;</td>
          <td class="paramname"><em>filterData</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int32_t *&#160;</td>
          <td class="paramname"><em>biasData</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="group__group__nn__kernel__data__structures.html#structcy__nn__fc__params__t">cy_nn_fc_params_t</a> *&#160;</td>
          <td class="paramname"><em>fcParam</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="group__group__nnlite__enums.html#ga384cb7d2feea111076bbd75ae43e60f6">cy_en_nnlite_fused_activation_t</a>&#160;</td>
          <td class="paramname"><em>actType</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="group__group__nn__kernel__data__structures.html#structcy__nn__act__intrpl__param__t">cy_nn_act_intrpl_param_t</a> *&#160;</td>
          <td class="paramname"><em>intrplParam</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Fully connected DMA mode kernel API, API will configure DMA descriptor pointing nnlite MEMIO configuration structure. </p>
<p >Valid scratch buffer should be passed in fcParam, scratch buffer will be used for nnlite MEMIO configuration structure, size of scratch buffer should be value return from Cy_NNLite_ScratchBufSize + Cy_NNLite_FC_ScratchBufSize. Cy_NNLite_FC_ScratchBufSize is required for case inputDims-&gt;dims[0] &gt; 1 CY_NNLITE_OP_QUEUED will be the return value on success After queuing kernel, DMA needs to be triggered by calling API Cy_TriggerNNLiteDMAQueue</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">inputData</td><td>activation buffer pointer</td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">outData</td><td>output buffer pointer</td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">inputDims</td><td>activation dimension pointer</td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">outputDims</td><td>output dimension pointer</td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">filterDims</td><td>filter dimension pointer</td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">filterData</td><td>filter data (weights or packed weights structure) pointer</td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">biasData</td><td>bias pointer N.b. 64-bit per value fo r16-bit activations</td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">fcParam</td><td>fully Connected parameter structure pointer</td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">actType</td><td>output activation type</td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">intrplParam</td><td>interpolation param for PWL <code>actType</code> activation</td></tr>
  </table>
  </dd>
</dl>
<dl class="retval"><dt>Return values</dt><dd>
  <table class="retval">
    <tr><td class="paramname">Refer</td><td><a class="el" href="group__group__nnlite__enums.html#ga8714c4a5105d4130fb67c76b0d9a1920">cy_en_nnlite_status_t</a> </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="gac23235aca7d94134af544c0e6ffe46d5" name="gac23235aca7d94134af544c0e6ffe46d5"></a>
<h2 class="memtitle"><span class="permalink"><a href="#gac23235aca7d94134af544c0e6ffe46d5">&#9670;&nbsp;</a></span>Cy_NNLite_Avgpool()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="group__group__nnlite__enums.html#ga8714c4a5105d4130fb67c76b0d9a1920">cy_en_nnlite_status_t</a> Cy_NNLite_Avgpool </td>
          <td>(</td>
          <td class="paramtype">const int8_t *&#160;</td>
          <td class="paramname"><em>inputData</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int8_t *&#160;</td>
          <td class="paramname"><em>outData</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="group__group__nn__kernel__data__structures.html#structcy__nn__dims__t">cy_nn_dims_t</a> *&#160;</td>
          <td class="paramname"><em>inputDims</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="group__group__nn__kernel__data__structures.html#structcy__nn__dims__t">cy_nn_dims_t</a> *&#160;</td>
          <td class="paramname"><em>outputDims</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="group__group__nn__kernel__data__structures.html#structcy__nn__dims__t">cy_nn_dims_t</a> *&#160;</td>
          <td class="paramname"><em>filterDims</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="group__group__nn__kernel__data__structures.html#structcy__nn__pool__params__t">cy_nn_pool_params_t</a> *&#160;</td>
          <td class="paramname"><em>avgpoolParam</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Average pool CPU mode kernel API, API will configure nnlite. </p>
<p >and then start nnlite operation. API will work in blocking mode if callback function in Kernel config structure is NULL, if valid callback function is passed in Kernel config, API will be non-blocking and callback function will be called after completion of layer, caller need to wait for callback function before calling another Kernel API, else error will be for other function</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">inputData</td><td>activation buffer pointer</td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">outData</td><td>output buffer pointer</td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">inputDims</td><td>activation dimension pointer</td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">outputDims</td><td>output dimension pointer</td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">filterDims</td><td>filter dimension pointer</td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">avgpoolParam</td><td>average pool parameter structure pointer</td></tr>
  </table>
  </dd>
</dl>
<dl class="retval"><dt>Return values</dt><dd>
  <table class="retval">
    <tr><td class="paramname">Refer</td><td><a class="el" href="group__group__nnlite__enums.html#ga8714c4a5105d4130fb67c76b0d9a1920">cy_en_nnlite_status_t</a> </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="ga02e850ef8f743ad3781e216f53e46ad4" name="ga02e850ef8f743ad3781e216f53e46ad4"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ga02e850ef8f743ad3781e216f53e46ad4">&#9670;&nbsp;</a></span>Cy_NNLite_AvgpoolDMA()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="group__group__nnlite__enums.html#ga8714c4a5105d4130fb67c76b0d9a1920">cy_en_nnlite_status_t</a> Cy_NNLite_AvgpoolDMA </td>
          <td>(</td>
          <td class="paramtype">const int8_t *&#160;</td>
          <td class="paramname"><em>inputData</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int8_t *&#160;</td>
          <td class="paramname"><em>outData</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="group__group__nn__kernel__data__structures.html#structcy__nn__dims__t">cy_nn_dims_t</a> *&#160;</td>
          <td class="paramname"><em>inputDims</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="group__group__nn__kernel__data__structures.html#structcy__nn__dims__t">cy_nn_dims_t</a> *&#160;</td>
          <td class="paramname"><em>outputDims</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="group__group__nn__kernel__data__structures.html#structcy__nn__dims__t">cy_nn_dims_t</a> *&#160;</td>
          <td class="paramname"><em>filterDims</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="group__group__nn__kernel__data__structures.html#structcy__nn__pool__params__t">cy_nn_pool_params_t</a> *&#160;</td>
          <td class="paramname"><em>avgpoolParam</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Average pool CPU mode kernel API, API will configure DMA descriptor pointing nnlite MEMIO configuration structure. </p>
<p >Valid scratch buffer should be passed in avgpoolParam, scratch buffer will be used for nnlite MEMIO configuration structure, size of scratch buffer should be value return from Cy_NNLite_ScratchBufSize. CY_NNLITE_OP_QUEUED will be the return value on success After queuing kernel, DMA needs to be triggered by calling API Cy_TriggerNNLiteDMAQueue</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">inputData</td><td>activation buffer pointer</td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">outData</td><td>output buffer pointer</td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">inputDims</td><td>activation dimension pointer</td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">outputDims</td><td>output dimension pointer</td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">filterDims</td><td>filter dimension pointer</td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">avgpoolParam</td><td>average pool parameter structure pointer</td></tr>
  </table>
  </dd>
</dl>
<dl class="retval"><dt>Return values</dt><dd>
  <table class="retval">
    <tr><td class="paramname">Refer</td><td><a class="el" href="group__group__nnlite__enums.html#ga8714c4a5105d4130fb67c76b0d9a1920">cy_en_nnlite_status_t</a> </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="ga7de6394709b01caddd5e1c9dbdbde3b4" name="ga7de6394709b01caddd5e1c9dbdbde3b4"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ga7de6394709b01caddd5e1c9dbdbde3b4">&#9670;&nbsp;</a></span>Cy_NNLite_Maxpool()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="group__group__nnlite__enums.html#ga8714c4a5105d4130fb67c76b0d9a1920">cy_en_nnlite_status_t</a> Cy_NNLite_Maxpool </td>
          <td>(</td>
          <td class="paramtype">const int8_t *&#160;</td>
          <td class="paramname"><em>inputData</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int8_t *&#160;</td>
          <td class="paramname"><em>outData</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="group__group__nn__kernel__data__structures.html#structcy__nn__dims__t">cy_nn_dims_t</a> *&#160;</td>
          <td class="paramname"><em>inputDims</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="group__group__nn__kernel__data__structures.html#structcy__nn__dims__t">cy_nn_dims_t</a> *&#160;</td>
          <td class="paramname"><em>outputDims</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="group__group__nn__kernel__data__structures.html#structcy__nn__dims__t">cy_nn_dims_t</a> *&#160;</td>
          <td class="paramname"><em>filterDims</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="group__group__nn__kernel__data__structures.html#structcy__nn__pool__params__t">cy_nn_pool_params_t</a> *&#160;</td>
          <td class="paramname"><em>poolParam</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Max pool CPU mode kernel API, API will configure nnlite. </p>
<p >and then start nnlite operation. API will work in blocking mode if callback function in Kernel config structure is NULL, if valid callback function is passed in Kernel config, API will be non-blocking and callback function will be called after completion of layer, caller need to wait for callback function before calling another Kernel API, else error will be for other function</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">inputData</td><td>activation buffer pointer</td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">outData</td><td>output buffer pointer</td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">inputDims</td><td>activation dimension pointer</td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">outputDims</td><td>output dimension pointer</td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">filterDims</td><td>filter dimension pointer</td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">poolParam</td><td>average pool parameter structure pointer</td></tr>
  </table>
  </dd>
</dl>
<dl class="retval"><dt>Return values</dt><dd>
  <table class="retval">
    <tr><td class="paramname">Refer</td><td><a class="el" href="group__group__nnlite__enums.html#ga8714c4a5105d4130fb67c76b0d9a1920">cy_en_nnlite_status_t</a> </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="gab3d59e53baf9fc619c5be3b8ece86221" name="gab3d59e53baf9fc619c5be3b8ece86221"></a>
<h2 class="memtitle"><span class="permalink"><a href="#gab3d59e53baf9fc619c5be3b8ece86221">&#9670;&nbsp;</a></span>Cy_NNLite_MaxpoolDMA()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="group__group__nnlite__enums.html#ga8714c4a5105d4130fb67c76b0d9a1920">cy_en_nnlite_status_t</a> Cy_NNLite_MaxpoolDMA </td>
          <td>(</td>
          <td class="paramtype">const int8_t *&#160;</td>
          <td class="paramname"><em>inputData</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int8_t *&#160;</td>
          <td class="paramname"><em>outData</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="group__group__nn__kernel__data__structures.html#structcy__nn__dims__t">cy_nn_dims_t</a> *&#160;</td>
          <td class="paramname"><em>inputDims</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="group__group__nn__kernel__data__structures.html#structcy__nn__dims__t">cy_nn_dims_t</a> *&#160;</td>
          <td class="paramname"><em>outputDims</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="group__group__nn__kernel__data__structures.html#structcy__nn__dims__t">cy_nn_dims_t</a> *&#160;</td>
          <td class="paramname"><em>filterDims</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="group__group__nn__kernel__data__structures.html#structcy__nn__pool__params__t">cy_nn_pool_params_t</a> *&#160;</td>
          <td class="paramname"><em>poolParam</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Max pool CPU mode kernel API, API will configure DMA descriptor pointing nnlite MEMIO configuration structure. </p>
<p >Valid scratch buffer should be passed in poolParam, scratch buffer will be used for nnlite MEMIO configuration structure, size of scratch buffer should be value return from Cy_NNLite_ScratchBufSize. CY_NNLITE_OP_QUEUED will be the return value on success After queuing kernel, DMA needs to be triggered by calling API Cy_TriggerNNLiteDMAQueue</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">inputData</td><td>activation buffer pointer</td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">outData</td><td>output buffer pointer</td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">inputDims</td><td>activation dimension pointer</td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">outputDims</td><td>output dimension pointer</td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">filterDims</td><td>filter dimension pointer</td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">poolParam</td><td>average pool parameter structure pointer</td></tr>
  </table>
  </dd>
</dl>
<dl class="retval"><dt>Return values</dt><dd>
  <table class="retval">
    <tr><td class="paramname">Refer</td><td><a class="el" href="group__group__nnlite__enums.html#ga8714c4a5105d4130fb67c76b0d9a1920">cy_en_nnlite_status_t</a> </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="ga1c8ba4f8b4baf9c33d9abebd583797ef" name="ga1c8ba4f8b4baf9c33d9abebd583797ef"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ga1c8ba4f8b4baf9c33d9abebd583797ef">&#9670;&nbsp;</a></span>Cy_NNLite_Scaling_Setup()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="group__group__nnlite__enums.html#ga8714c4a5105d4130fb67c76b0d9a1920">cy_en_nnlite_status_t</a> Cy_NNLite_Scaling_Setup </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="group__group__nn__kernel__data__structures.html#structcy__nn__scaling__t">cy_nn_scaling_t</a> *&#160;</td>
          <td class="paramname"><em>ss</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">float&#160;</td>
          <td class="paramname"><em>lhs_scale</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">float&#160;</td>
          <td class="paramname"><em>rhs_scale</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">float&#160;</td>
          <td class="paramname"><em>output_scale</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="group__group__nnlite__enums.html#gab1d317e2be183e109725321de8c31bdb">cy_en_nnlite_activation_size_t</a>&#160;</td>
          <td class="paramname"><em>in_size</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="group__group__nnlite__enums.html#ga12a9e134b477430f9d2562c18e7d3620">cy_en_nnlite_op_t</a>&#160;</td>
          <td class="paramname"><em>op_type</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="group__group__nnlite__enums.html#ga384cb7d2feea111076bbd75ae43e60f6">cy_en_nnlite_fused_activation_t</a>&#160;</td>
          <td class="paramname"><em>act_type</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Precomputation of NPU scaling factor settings for NPU binary operations. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">ss</td><td>Scaling factors NPU Operation </td></tr>
    <tr><td class="paramname">lhs_scale</td><td>Scale factor for "left hand side" input values </td></tr>
    <tr><td class="paramname">rhs_scale</td><td>Scale factor for "right hand side" input values </td></tr>
    <tr><td class="paramname">output_scale</td><td>Scale factor for final output values. </td></tr>
    <tr><td class="paramname">input_size</td><td>Bitwidth of (MAC) input values. </td></tr>
    <tr><td class="paramname">op_type</td><td>ALU Operation </td></tr>
    <tr><td class="paramname">act_type</td><td>Fused action function to be applied </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>cy_en_nnlite_status_t Success status (checks for unsupported ops/activations)</dd></dl>
<p>TODO Create some special-case "fast path" versions (e.g. for use inside LSTM)? Support per-filter and per-row setup for Conv and fully connected ops </p>

</div>
</div>
<a id="ga3345c26bd760af24bc030099b7c4ebbc" name="ga3345c26bd760af24bc030099b7c4ebbc"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ga3345c26bd760af24bc030099b7c4ebbc">&#9670;&nbsp;</a></span>Cy_NNLite_Scaling_Q_Setup()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void Cy_NNLite_Scaling_Q_Setup </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="group__group__nn__kernel__data__structures.html#structcy__nn__scaling__t">cy_nn_scaling_t</a> *&#160;</td>
          <td class="paramname"><em>ss</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Set scaling configuration to "no scaling" (fast) </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">ss</td><td>Point to Scaling configuration to be </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="gaffaef8a986e014bf3b106016d8297062" name="gaffaef8a986e014bf3b106016d8297062"></a>
<h2 class="memtitle"><span class="permalink"><a href="#gaffaef8a986e014bf3b106016d8297062">&#9670;&nbsp;</a></span>Cy_NNLite_AddSubMul()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="group__group__nnlite__enums.html#ga8714c4a5105d4130fb67c76b0d9a1920">cy_en_nnlite_status_t</a> Cy_NNLite_AddSubMul </td>
          <td>(</td>
          <td class="paramtype">const int8_t *&#160;</td>
          <td class="paramname"><em>lhsData</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int8_t *&#160;</td>
          <td class="paramname"><em>rhsData</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int8_t *&#160;</td>
          <td class="paramname"><em>outData</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="group__group__nn__kernel__data__structures.html#structcy__nn__dims__t">cy_nn_dims_t</a> *&#160;</td>
          <td class="paramname"><em>lhsDims</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="group__group__nn__kernel__data__structures.html#structcy__nn__dims__t">cy_nn_dims_t</a> *&#160;</td>
          <td class="paramname"><em>rhsOutDims</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="group__group__nn__kernel__data__structures.html#structcy__nn__pwise__binary__params__t">cy_nn_pwise_binary_params_t</a> *&#160;</td>
          <td class="paramname"><em>pwParams</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="group__group__nnlite__enums.html#ga12a9e134b477430f9d2562c18e7d3620">cy_en_nnlite_op_t</a>&#160;</td>
          <td class="paramname"><em>op_type</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="group__group__nnlite__enums.html#ga384cb7d2feea111076bbd75ae43e60f6">cy_en_nnlite_fused_activation_t</a>&#160;</td>
          <td class="paramname"><em>act_type</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Generic binary op CPU mode kernel API, API will configure nnlite. </p>
<p >and then start nnlite operation. API will work in blocking mode if callback function in Kernel config structure is NULL, if valid callback function is passed in Kernel config, API will be non-blocking and callback function will be called after completion of layer, caller need to wait for callback function before calling another Kernel API, else error will be for other function</p>
<p >Limited broadcasting is supported. For rhsOuputDims [D_1,..,D_m,..,D_n] and lhsDims = [1,...,Dm,..Dn] lhsData is repeated for the [D_1,...,D_(m-1)] major coordinate positions in rhsData.</p>
<p >Internally implemented as "depthwise" summation using 1x1 kernel.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">lhsData</td><td>lhs input tensor buffer pointer</td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">rhsData</td><td>rhs input tensor pointer (elts repeated if less elts than lhs)</td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">outData</td><td>output buffer pointer</td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">lhsDims</td><td>dimensions of lhs argument (repeated if less elts than inputDims )</td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">rhsOutDims</td><td>dimensions of rhs argument and output.</td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pwParams</td><td>Pointwise op params (lhs and output rescaling factors)</td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">op_type</td><td>MAC-unit operating mode to configure</td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">act_type</td><td>Activation function to configure</td></tr>
  </table>
  </dd>
</dl>
<dl class="retval"><dt>Return values</dt><dd>
  <table class="retval">
    <tr><td class="paramname">Refer</td><td><a class="el" href="group__group__nnlite__enums.html#ga8714c4a5105d4130fb67c76b0d9a1920">cy_en_nnlite_status_t</a> </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="gab9f8f7bf974e85cc9f617db483922756" name="gab9f8f7bf974e85cc9f617db483922756"></a>
<h2 class="memtitle"><span class="permalink"><a href="#gab9f8f7bf974e85cc9f617db483922756">&#9670;&nbsp;</a></span>Cy_NNLite_AddSubMulDMA()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="group__group__nnlite__enums.html#ga8714c4a5105d4130fb67c76b0d9a1920">cy_en_nnlite_status_t</a> Cy_NNLite_AddSubMulDMA </td>
          <td>(</td>
          <td class="paramtype">const int8_t *&#160;</td>
          <td class="paramname"><em>lhsData</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int8_t *&#160;</td>
          <td class="paramname"><em>rhsData</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int8_t *&#160;</td>
          <td class="paramname"><em>outData</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="group__group__nn__kernel__data__structures.html#structcy__nn__dims__t">cy_nn_dims_t</a> *&#160;</td>
          <td class="paramname"><em>lhsDims</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="group__group__nn__kernel__data__structures.html#structcy__nn__dims__t">cy_nn_dims_t</a> *&#160;</td>
          <td class="paramname"><em>rhsOutDims</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="group__group__nn__kernel__data__structures.html#structcy__nn__pwise__binary__params__t">cy_nn_pwise_binary_params_t</a> *&#160;</td>
          <td class="paramname"><em>pwParams</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="group__group__nnlite__enums.html#ga12a9e134b477430f9d2562c18e7d3620">cy_en_nnlite_op_t</a>&#160;</td>
          <td class="paramname"><em>op_type</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="group__group__nnlite__enums.html#ga384cb7d2feea111076bbd75ae43e60f6">cy_en_nnlite_fused_activation_t</a>&#160;</td>
          <td class="paramname"><em>act_type</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Generic binary op CPU mode kernel API, API will configure DMA descriptor pointing nnlite MEMIO configuration structure. </p>
<p >Valid scratch buffer should be passed in pwParams, scratch buffer will be used for nnlite MEMIO configuration structure, size of scratch buffer should be value return from Cy_NNLite_ScratchBufSize. CY_NNLITE_OP_QUEUED will be the return value on success After queuing kernel, DMA needs to be triggered by calling API Cy_TriggerNNLiteDMAQueue</p>
<p >Limited broadcasting is supported. For rhsOuputDims [D_1,..,D_m,..,D_n] and lhsDims = [1,...,Dm,..Dn] lhsData is repeated for the [D_1,...,D_(m-1)] major coordinate positions in rhsData.</p>
<p >Internally implemented as "depthwise" summation using 1x1 kernel.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">lhsData</td><td>lhs input tensor buffer pointer</td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">rhsData</td><td>rhs input tensor pointer (elts repeated if less elts than lhs)</td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">outData</td><td>output buffer pointer</td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">lhsDims</td><td>dimensions of lhs argument (repeated if less elts than inputDims )</td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">rhsOutDims</td><td>dimensions of rhs argument and output.</td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pwParams</td><td>Pointwise op params (lhs and output rescaling factors)</td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">op_type</td><td>MAC-unit operating mode to configure</td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">act_type</td><td>Activation function to configure</td></tr>
  </table>
  </dd>
</dl>
<dl class="retval"><dt>Return values</dt><dd>
  <table class="retval">
    <tr><td class="paramname">Refer</td><td><a class="el" href="group__group__nnlite__enums.html#ga8714c4a5105d4130fb67c76b0d9a1920">cy_en_nnlite_status_t</a> </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="ga1a1c20d1fd2b23d54ea782ccfb2e277d" name="ga1a1c20d1fd2b23d54ea782ccfb2e277d"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ga1a1c20d1fd2b23d54ea782ccfb2e277d">&#9670;&nbsp;</a></span>Cy_NNLite_Add()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="group__group__nnlite__enums.html#ga8714c4a5105d4130fb67c76b0d9a1920">cy_en_nnlite_status_t</a> Cy_NNLite_Add </td>
          <td>(</td>
          <td class="paramtype">const int8_t *&#160;</td>
          <td class="paramname"><em>lhsData</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int8_t *&#160;</td>
          <td class="paramname"><em>rhsData</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int8_t *&#160;</td>
          <td class="paramname"><em>outData</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="group__group__nn__kernel__data__structures.html#structcy__nn__dims__t">cy_nn_dims_t</a> *&#160;</td>
          <td class="paramname"><em>lhsDims</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="group__group__nn__kernel__data__structures.html#structcy__nn__dims__t">cy_nn_dims_t</a> *&#160;</td>
          <td class="paramname"><em>rhsOutDims</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="group__group__nn__kernel__data__structures.html#structcy__nn__pwise__binary__params__t">cy_nn_pwise_binary_params_t</a> *&#160;</td>
          <td class="paramname"><em>pwParams</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Pointwise addition operation. </p>
<p >Pointwise addition CPU mode kernel API, API will configure nnlite. and then start nnlite operation. API will work in blocking mode if callback function in Kernel config structure is NULL, if valid callback function is passed in Kernel config, API will be non-blocking and callback function will be called after completion of layer, caller need to wait for callback function before calling another Kernel API, else error will be for other function</p>
<p >Limited broadcasting is supported. For rhsOuputDims [D_1,..,D_m,..,D_n] and lhsDims = [1,...,Dm,..Dn] lhsData is repeated for the [D_1,...,D_(m-1)] major coordinate positions in rhsData. Internally implemented as "depthwise" summation using 1x1 kernel.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">lhsData</td><td>lhs input tensor buffer pointer</td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">rhsData</td><td>rhs input tensor pointer (elts repeated if less elts than lhs)</td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">outData</td><td>output buffer pointer</td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">lhsDims</td><td>dimensions of lhs argument (repeated if less elts than inputDims )</td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">rhsOutDims</td><td>rhs argument and output.</td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pwParams</td><td>Pointwise op params (lhs and output rescaling factors)</td></tr>
  </table>
  </dd>
</dl>
<dl class="retval"><dt>Return values</dt><dd>
  <table class="retval">
    <tr><td class="paramname">Refer</td><td><a class="el" href="group__group__nnlite__enums.html#ga8714c4a5105d4130fb67c76b0d9a1920">cy_en_nnlite_status_t</a></td></tr>
  </table>
  </dd>
</dl>
<p>Pointwise addition operation.</p>
<p >Delegates to <code>Cy_NNLite_AddSub</code> </p>

</div>
</div>
<a id="ga162d327e497e433aa38c1eff3adce291" name="ga162d327e497e433aa38c1eff3adce291"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ga162d327e497e433aa38c1eff3adce291">&#9670;&nbsp;</a></span>Cy_NNLite_AddDMA()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="group__group__nnlite__enums.html#ga8714c4a5105d4130fb67c76b0d9a1920">cy_en_nnlite_status_t</a> Cy_NNLite_AddDMA </td>
          <td>(</td>
          <td class="paramtype">const int8_t *&#160;</td>
          <td class="paramname"><em>lhsData</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int8_t *&#160;</td>
          <td class="paramname"><em>rhsData</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int8_t *&#160;</td>
          <td class="paramname"><em>outData</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="group__group__nn__kernel__data__structures.html#structcy__nn__dims__t">cy_nn_dims_t</a> *&#160;</td>
          <td class="paramname"><em>lhsDims</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="group__group__nn__kernel__data__structures.html#structcy__nn__dims__t">cy_nn_dims_t</a> *&#160;</td>
          <td class="paramname"><em>rhsOutDims</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="group__group__nn__kernel__data__structures.html#structcy__nn__pwise__binary__params__t">cy_nn_pwise_binary_params_t</a> *&#160;</td>
          <td class="paramname"><em>pwParams</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Pointwise addition operation. </p>
<p >Pointwise addition DMA mode kernel API, API will configure DMA descriptor pointing nnlite MEMIO configuration structure. Valid scratch buffer should be passed in pwParams, scratch buffer will be used for nnlite MEMIO configuration structure, size of scratch buffer should be value return from Cy_NNLite_ScratchBufSize. CY_NNLITE_OP_QUEUED will be the return value on success After queuing kernel, DMA needs to be triggered by calling API Cy_TriggerNNLiteDMAQueue</p>
<p >Limited broadcasting is supported. For rhsOuputDims [D_1,..,D_m,..,D_n] and lhsDims = [1,...,Dm,..Dn] lhsData is repeated for the [D_1,...,D_(m-1)] major coordinate positions in rhsData. Internally implemented as "depthwise" summation using 1x1 kernel.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">lhsData</td><td>lhs input tensor buffer pointer</td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">rhsData</td><td>rhs input tensor pointer (elts repeated if less elts than lhs)</td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">outData</td><td>output buffer pointer</td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">lhsDims</td><td>dimensions of lhs argument (repeated if less elts than inputDims )</td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">rhsOutDims</td><td>rhs argument and output.</td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pwParams</td><td>Pointwise op params (lhs and output rescaling factors)</td></tr>
  </table>
  </dd>
</dl>
<dl class="retval"><dt>Return values</dt><dd>
  <table class="retval">
    <tr><td class="paramname">Refer</td><td><a class="el" href="group__group__nnlite__enums.html#ga8714c4a5105d4130fb67c76b0d9a1920">cy_en_nnlite_status_t</a> </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="ga0710ea5b33d8520b6f3eba69c90e3516" name="ga0710ea5b33d8520b6f3eba69c90e3516"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ga0710ea5b33d8520b6f3eba69c90e3516">&#9670;&nbsp;</a></span>Cy_NNLite_Sub()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="group__group__nnlite__enums.html#ga8714c4a5105d4130fb67c76b0d9a1920">cy_en_nnlite_status_t</a> Cy_NNLite_Sub </td>
          <td>(</td>
          <td class="paramtype">const int8_t *&#160;</td>
          <td class="paramname"><em>lhsData</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int8_t *&#160;</td>
          <td class="paramname"><em>rhsData</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int8_t *&#160;</td>
          <td class="paramname"><em>outData</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="group__group__nn__kernel__data__structures.html#structcy__nn__dims__t">cy_nn_dims_t</a> *&#160;</td>
          <td class="paramname"><em>lhsDims</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="group__group__nn__kernel__data__structures.html#structcy__nn__dims__t">cy_nn_dims_t</a> *&#160;</td>
          <td class="paramname"><em>rhsOutDims</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="group__group__nn__kernel__data__structures.html#structcy__nn__pwise__binary__params__t">cy_nn_pwise_binary_params_t</a> *&#160;</td>
          <td class="paramname"><em>pwParams</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">bool&#160;</td>
          <td class="paramname"><em>left_from_right</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Pointwise addition operation. </p>
<p >Pointwise addition CPU mode kernel API, API will configure nnlite and then start nnlite operation.API will work in blocking mode if callback function in Kernel config structure is NULL, if valid callback function is passed in Kernel config, API will be non-blocking and callback function will be called after completion of layer, caller need to wait for callback function before calling another Kernel API, else error will be for other function</p>
<p >Limited broadcasting is supported. For rhsOuputDims [D_1,..,D_m,..,D_n] and lhsDims = [1,...,Dm,..Dn] lhsData is repeated for the [D_1,...,D_(m-1)] major coordinate positions in rhsData. Internally implemented as "depthwise" summation using 1x1 kernel.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">lhsData</td><td>lhs input tensor buffer pointer</td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">rhsData</td><td>rhs input tensor pointer (elts repeated if less elts than lhs)</td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">outData</td><td>output buffer pointer</td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">lhsDims</td><td>dimensions of lhs argument (repeated if less elts than inputDims )</td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">rhsOutDims</td><td>rhs argument and output.</td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pwParams</td><td>Pointwise op params (lhs and output rescaling factors)</td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">left_from_right</td><td>Compute rhsData - lhsData rather than lhsData - rhsData</td></tr>
  </table>
  </dd>
</dl>
<dl class="retval"><dt>Return values</dt><dd>
  <table class="retval">
    <tr><td class="paramname">Refer</td><td><a class="el" href="group__group__nnlite__enums.html#ga8714c4a5105d4130fb67c76b0d9a1920">cy_en_nnlite_status_t</a></td></tr>
  </table>
  </dd>
</dl>
<p>Pointwise addition operation.</p>
<p >Delegates to <code>Cy_NNLite_AddSub</code> </p>

</div>
</div>
<a id="ga8ed2232c6d1557f3e7d0450cb5c7d516" name="ga8ed2232c6d1557f3e7d0450cb5c7d516"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ga8ed2232c6d1557f3e7d0450cb5c7d516">&#9670;&nbsp;</a></span>Cy_NNLite_SubDMA()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="group__group__nnlite__enums.html#ga8714c4a5105d4130fb67c76b0d9a1920">cy_en_nnlite_status_t</a> Cy_NNLite_SubDMA </td>
          <td>(</td>
          <td class="paramtype">const int8_t *&#160;</td>
          <td class="paramname"><em>lhsData</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int8_t *&#160;</td>
          <td class="paramname"><em>rhsData</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int8_t *&#160;</td>
          <td class="paramname"><em>outData</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="group__group__nn__kernel__data__structures.html#structcy__nn__dims__t">cy_nn_dims_t</a> *&#160;</td>
          <td class="paramname"><em>lhsDims</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="group__group__nn__kernel__data__structures.html#structcy__nn__dims__t">cy_nn_dims_t</a> *&#160;</td>
          <td class="paramname"><em>rhsOutDims</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="group__group__nn__kernel__data__structures.html#structcy__nn__pwise__binary__params__t">cy_nn_pwise_binary_params_t</a> *&#160;</td>
          <td class="paramname"><em>pwParams</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">bool&#160;</td>
          <td class="paramname"><em>left_from_right</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Pointwise addition operation. </p>
<p >Pointwise addition DMA mode kernel API, API will configure DMA descriptor pointing nnlite MEMIO configuration structure. Valid scratch buffer should be passed in pwParams, scratch buffer will be used for nnlite MEMIO configuration structure, size of scratch buffer should be value return from Cy_NNLite_ScratchBufSize. CY_NNLITE_OP_QUEUED will be the return value on success After queuing kernel, DMA needs to be triggered by calling API Cy_TriggerNNLiteDMAQueue</p>
<p >Limited broadcasting is supported. For rhsOuputDims [D_1,..,D_m,..,D_n] and lhsDims = [1,...,Dm,..Dn] lhsData is repeated for the [D_1,...,D_(m-1)] major coordinate positions in rhsData. Internally implemented as "depthwise" summation using 1x1 kernel.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">lhsData</td><td>lhs input tensor buffer pointer</td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">rhsData</td><td>rhs input tensor pointer (elts repeated if less elts than lhs)</td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">outData</td><td>output buffer pointer</td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">lhsDims</td><td>dimensions of lhs argument (repeated if less elts than inputDims )</td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">rhsOutDims</td><td>rhs argument and output.</td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pwParams</td><td>Pointwise op params (lhs and output rescaling factors)</td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">left_from_right</td><td>Compute rhsData - lhsData rather than lhsData - rhsData</td></tr>
  </table>
  </dd>
</dl>
<dl class="retval"><dt>Return values</dt><dd>
  <table class="retval">
    <tr><td class="paramname">Refer</td><td><a class="el" href="group__group__nnlite__enums.html#ga8714c4a5105d4130fb67c76b0d9a1920">cy_en_nnlite_status_t</a> </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="ga37d624dd67d791c09e958fb90b68f374" name="ga37d624dd67d791c09e958fb90b68f374"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ga37d624dd67d791c09e958fb90b68f374">&#9670;&nbsp;</a></span>Cy_NNLite_Mul()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="group__group__nnlite__enums.html#ga8714c4a5105d4130fb67c76b0d9a1920">cy_en_nnlite_status_t</a> Cy_NNLite_Mul </td>
          <td>(</td>
          <td class="paramtype">const int8_t *&#160;</td>
          <td class="paramname"><em>lhsData</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int8_t *&#160;</td>
          <td class="paramname"><em>rhsData</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int8_t *&#160;</td>
          <td class="paramname"><em>outData</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="group__group__nn__kernel__data__structures.html#structcy__nn__dims__t">cy_nn_dims_t</a> *&#160;</td>
          <td class="paramname"><em>lhsDims</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="group__group__nn__kernel__data__structures.html#structcy__nn__dims__t">cy_nn_dims_t</a> *&#160;</td>
          <td class="paramname"><em>rhsOutDims</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="group__group__nn__kernel__data__structures.html#structcy__nn__pwise__binary__params__t">cy_nn_pwise_binary_params_t</a> *&#160;</td>
          <td class="paramname"><em>pwParams</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>multiplication </p>
<p >Pointwise multiplication CPU mode kernel API, API will configure nnlite and then start nnlite operation. API will work in blocking mode if callback function in Kernel config structure is NULL, if valid callback function is passed in Kernel config, API will be non-blocking and callback function will be called after completion of layer, caller need to wait for callback function before calling another Kernel API, else error will be for other function</p>
<p >Limited broadcasting is supported. For rhsOuputDims [D_1,..,D_m,..,D_n] and lhsDims = [1,...,Dm,..Dn] lhsData is repeated for the [D_1,...,D_(m-1)] major coordinate positions in rhsData. Internally implemented as "depthwise" summation using 1x1 kernel.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">lhsData</td><td>lhs input tensor buffer pointer</td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">rhsData</td><td>rhs input tensor pointer (elts repeated if less elts than lhs)</td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">outData</td><td>output buffer pointer</td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">lhsDims</td><td>dimensions of lhs argument (repeated if less elts than inputDims )</td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">rhsOutDims</td><td>rhs argument and output.</td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pwParams</td><td>Pointwise op params (lhs and output rescaling factors)</td></tr>
  </table>
  </dd>
</dl>
<dl class="retval"><dt>Return values</dt><dd>
  <table class="retval">
    <tr><td class="paramname">Refer</td><td><a class="el" href="group__group__nnlite__enums.html#ga8714c4a5105d4130fb67c76b0d9a1920">cy_en_nnlite_status_t</a></td></tr>
  </table>
  </dd>
</dl>
<p>multiplication</p>
<p >Delegates to <code>Cy_NNLite_AddSubMul</code> </p>

</div>
</div>
<a id="ga754ee6761941470c18af83f1310758f5" name="ga754ee6761941470c18af83f1310758f5"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ga754ee6761941470c18af83f1310758f5">&#9670;&nbsp;</a></span>Cy_NNLite_MulDMA()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="group__group__nnlite__enums.html#ga8714c4a5105d4130fb67c76b0d9a1920">cy_en_nnlite_status_t</a> Cy_NNLite_MulDMA </td>
          <td>(</td>
          <td class="paramtype">const int8_t *&#160;</td>
          <td class="paramname"><em>lhsData</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int8_t *&#160;</td>
          <td class="paramname"><em>rhsData</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int8_t *&#160;</td>
          <td class="paramname"><em>outData</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="group__group__nn__kernel__data__structures.html#structcy__nn__dims__t">cy_nn_dims_t</a> *&#160;</td>
          <td class="paramname"><em>lhsDims</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="group__group__nn__kernel__data__structures.html#structcy__nn__dims__t">cy_nn_dims_t</a> *&#160;</td>
          <td class="paramname"><em>rhsOutDims</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="group__group__nn__kernel__data__structures.html#structcy__nn__pwise__binary__params__t">cy_nn_pwise_binary_params_t</a> *&#160;</td>
          <td class="paramname"><em>pwParams</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Pointwise multiplication with simple broadcast. </p>
<p >Pointwise multiplication DMA mode kernel API, API will configure DMA descriptor pointing nnlite MEMIO configuration structure. Valid scratch buffer should be passed in pwParams, scratch buffer will be used for nnlite MEMIO configuration structure,size of scratch buffer should be value return from Cy_NNLite_ScratchBufSize. CY_NNLITE_OP_QUEUED will be the return value on success After queuing kernel, DMA needs to be triggered by calling API Cy_TriggerNNLiteDMAQueue</p>
<p >Limited broadcasting is supported. For rhsOuputDims [D_1,..,D_m,..,D_n] and lhsDims = [1,...,Dm,..Dn] lhsData is repeated for the [D_1,...,D_(m-1)] major coordinate positions in rhsData. Internally implemented as "depthwise" summation using 1x1 kernel.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">lhsData</td><td>lhs input tensor buffer pointer</td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">rhsData</td><td>rhs input tensor pointer (elts repeated if less elts than lhs)</td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">outData</td><td>output buffer pointer</td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">lhsDims</td><td>dimensions of lhs argument (repeated if less elts than inputDims )</td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">rhsOutDims</td><td>rhs argument and output.</td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pwParams</td><td>Pointwise op params (lhs and output rescaling factors)</td></tr>
  </table>
  </dd>
</dl>
<dl class="retval"><dt>Return values</dt><dd>
  <table class="retval">
    <tr><td class="paramname">Refer</td><td><a class="el" href="group__group__nnlite__enums.html#ga8714c4a5105d4130fb67c76b0d9a1920">cy_en_nnlite_status_t</a> </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="ga275a1c8f56cf804ffb6443bd68686868" name="ga275a1c8f56cf804ffb6443bd68686868"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ga275a1c8f56cf804ffb6443bd68686868">&#9670;&nbsp;</a></span>Cy_NNLite_Activation()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="group__group__nnlite__enums.html#ga8714c4a5105d4130fb67c76b0d9a1920">cy_en_nnlite_status_t</a> Cy_NNLite_Activation </td>
          <td>(</td>
          <td class="paramtype">const int8_t *&#160;</td>
          <td class="paramname"><em>inData</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int8_t *&#160;</td>
          <td class="paramname"><em>outData</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="group__group__nn__kernel__data__structures.html#structcy__nn__dims__t">cy_nn_dims_t</a> *&#160;</td>
          <td class="paramname"><em>inoutDims</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="group__group__nn__kernel__data__structures.html#structcy__nn__pwise__unary__params__t">cy_nn_pwise_unary_params_t</a> *&#160;</td>
          <td class="paramname"><em>actParams</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="group__group__nnlite__enums.html#ga384cb7d2feea111076bbd75ae43e60f6">cy_en_nnlite_fused_activation_t</a>&#160;</td>
          <td class="paramname"><em>act_type</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="group__group__nn__kernel__data__structures.html#structcy__nn__act__intrpl__param__t">cy_nn_act_intrpl_param_t</a> *&#160;</td>
          <td class="paramname"><em>intrplParam</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Unfused Activation function CPU mode kernel API, API will configure nnlite and then start nnlite operation. </p>
<p >API will work in blocking mode if callback function in Kernel config structure is NULL, if valid callback function is passed in Kernel config, API will be non-blocking and callback function will be called after completion of layer, caller need to wait for callback function before calling another Kernel API, else error will be for other function</p>
<p >Internally implemented as "depthwise" operation on 1x1xC input</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">inData</td><td>rhs input tensor pointer (elts repeated if less elts than lhs)</td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">outData</td><td>output buffer pointer</td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">inoutDims</td><td>rhs argument and output.</td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">actParams</td><td>unfused activation op params (lhs and output rescaling factors)</td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">act_type</td><td>Activation function to apply.</td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">intrplParam</td><td>interpolation param for PWL output activation , null = nothing set</td></tr>
  </table>
  </dd>
</dl>
<dl class="retval"><dt>Return values</dt><dd>
  <table class="retval">
    <tr><td class="paramname">Refer</td><td><a class="el" href="group__group__nnlite__enums.html#ga8714c4a5105d4130fb67c76b0d9a1920">cy_en_nnlite_status_t</a></td></tr>
  </table>
  </dd>
</dl>
<p>Callback function from kernel config structure will be called after completion of layer. Kernel config structure should point to valid callback function.</p>
<p >Internally implemented as "depthwise" operation on 1x1xC input</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">inData</td><td>rhs input tensor pointer (elts repeated if less elts than lhs)</td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">outData</td><td>output buffer pointer</td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">inoutDims</td><td>rhs argument and output.</td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">actParams</td><td>unfused activation op params (lhs and output rescaling factors)</td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">act_type</td><td>Activation function to apply.</td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">intrplParam</td><td>interpolation param for PWL output activation , null = nothing set</td></tr>
  </table>
  </dd>
</dl>
<dl class="retval"><dt>Return values</dt><dd>
  <table class="retval">
    <tr><td class="paramname">Refer</td><td><a class="el" href="group__group__nnlite__enums.html#ga8714c4a5105d4130fb67c76b0d9a1920">cy_en_nnlite_status_t</a> </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="gab3331f4c70fb2fd0263ae5a13313fa6d" name="gab3331f4c70fb2fd0263ae5a13313fa6d"></a>
<h2 class="memtitle"><span class="permalink"><a href="#gab3331f4c70fb2fd0263ae5a13313fa6d">&#9670;&nbsp;</a></span>Cy_NNLite_ActivationDMA()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="group__group__nnlite__enums.html#ga8714c4a5105d4130fb67c76b0d9a1920">cy_en_nnlite_status_t</a> Cy_NNLite_ActivationDMA </td>
          <td>(</td>
          <td class="paramtype">const int8_t *&#160;</td>
          <td class="paramname"><em>inData</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int8_t *&#160;</td>
          <td class="paramname"><em>outData</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="group__group__nn__kernel__data__structures.html#structcy__nn__dims__t">cy_nn_dims_t</a> *&#160;</td>
          <td class="paramname"><em>inoutDims</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="group__group__nn__kernel__data__structures.html#structcy__nn__pwise__unary__params__t">cy_nn_pwise_unary_params_t</a> *&#160;</td>
          <td class="paramname"><em>actParams</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="group__group__nnlite__enums.html#ga384cb7d2feea111076bbd75ae43e60f6">cy_en_nnlite_fused_activation_t</a>&#160;</td>
          <td class="paramname"><em>act_type</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="group__group__nn__kernel__data__structures.html#structcy__nn__act__intrpl__param__t">cy_nn_act_intrpl_param_t</a> *&#160;</td>
          <td class="paramname"><em>intrplParam</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Unfused Activation function DMA mode kernel API,API will configure DMA descriptor pointing nnlite MEMIO configuration structure. </p>
<p >Valid scratch buffer should be passed in actParams, scratch buffer will be used for nnlite MEMIO configuration structure,size of scratch buffer should be value return from Cy_NNLite_ScratchBufSize. CY_NNLITE_OP_QUEUED will be the return value on success After queuing kernel, DMA needs to be triggered by calling API Cy_TriggerNNLiteDMAQueue</p>
<p >Internally implemented as "depthwise" operation on 1x1xC input</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">inData</td><td>rhs input tensor pointer (elts repeated if less elts than lhs)</td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">outData</td><td>output buffer pointer</td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">inoutDims</td><td>rhs argument and output.</td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">actParams</td><td>unfused activation op params (lhs and output rescaling factors)</td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">act_type</td><td>Activation function to apply.</td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">intrplParam</td><td>interpolation param for PWL output activation , null = nothing set</td></tr>
  </table>
  </dd>
</dl>
<dl class="retval"><dt>Return values</dt><dd>
  <table class="retval">
    <tr><td class="paramname">Refer</td><td><a class="el" href="group__group__nnlite__enums.html#ga8714c4a5105d4130fb67c76b0d9a1920">cy_en_nnlite_status_t</a> </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="ga2c0e42bffa7ef0bdee32c41029c1795f" name="ga2c0e42bffa7ef0bdee32c41029c1795f"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ga2c0e42bffa7ef0bdee32c41029c1795f">&#9670;&nbsp;</a></span>Cy_NNLite_LayerNorm()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="group__group__nnlite__enums.html#ga8714c4a5105d4130fb67c76b0d9a1920">cy_en_nnlite_status_t</a> Cy_NNLite_LayerNorm </td>
          <td>(</td>
          <td class="paramtype">const int8_t *&#160;</td>
          <td class="paramname"><em>inputData</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int8_t *&#160;</td>
          <td class="paramname"><em>outputData</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="group__group__nn__kernel__data__structures.html#structcy__nn__dims__t">cy_nn_dims_t</a> *&#160;</td>
          <td class="paramname"><em>inputDims</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="group__group__nn__kernel__data__structures.html#structcy__nn__dims__t">cy_nn_dims_t</a> *&#160;</td>
          <td class="paramname"><em>outputDims</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="group__group__nn__kernel__data__structures.html#structcy__nn__layernorm__params__t">cy_nn_layernorm_params_t</a> *&#160;</td>
          <td class="paramname"><em>lnParams</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Compute composite LayerNorm operation. </p>
<dl class="section note"><dt>Note</dt><dd>This is a "macro" kernel requiring multiple primitive NNLite operations to compute.</dd></dl>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">inputData</td><td>Input tensor data </td></tr>
    <tr><td class="paramname">outputData</td><td>Output tensor data (MUST be distinct from <code>inData</code>) </td></tr>
    <tr><td class="paramname">inputDims</td><td>Input dimension pointer </td></tr>
    <tr><td class="paramname">outputDims</td><td>Output dimension pointer </td></tr>
    <tr><td class="paramname">lnParams</td><td>LayerNorm parameter structure pointer. </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>cy_en_nnlite_status_t</dd></dl>
<dl class="section note"><dt>Note</dt><dd>This is a "macro" kernel requiring multiple primitive NNLite operations to compute.</dd></dl>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">inData</td><td>Input tensor data </td></tr>
    <tr><td class="paramname">outData</td><td>Output tensor data (MUST be distinct from <code>inData</code>) </td></tr>
    <tr><td class="paramname">inputDims</td><td>Input dimension pointer </td></tr>
    <tr><td class="paramname">outputDims</td><td>Output dimension pointer </td></tr>
    <tr><td class="paramname">lnParam</td><td>LayerNorm parameter structure pointer. </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>cy_en_nnlite_status_t </dd></dl>

</div>
</div>
<a id="ga39fe05b891ec370a3c80098fc0c226ec" name="ga39fe05b891ec370a3c80098fc0c226ec"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ga39fe05b891ec370a3c80098fc0c226ec">&#9670;&nbsp;</a></span>Cy_NNLite_Byte_Copy()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="group__group__nnlite__enums.html#ga8714c4a5105d4130fb67c76b0d9a1920">cy_en_nnlite_status_t</a> Cy_NNLite_Byte_Copy </td>
          <td>(</td>
          <td class="paramtype">const int8_t *&#160;</td>
          <td class="paramname"><em>inData</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int8_t *&#160;</td>
          <td class="paramname"><em>outData</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">uint32_t&#160;</td>
          <td class="paramname"><em>count</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Byte block copy using NNLite. </p>
<p >Internally implemented as "depthwise" operation on 1x1xC input</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">inData</td><td>address start byte vector to be copied</td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">outData</td><td>destination start address</td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">count</td><td>Number of bytes to be copied</td></tr>
  </table>
  </dd>
</dl>
<dl class="retval"><dt>Return values</dt><dd>
  <table class="retval">
    <tr><td class="paramname">Refer</td><td><a class="el" href="group__group__nnlite__enums.html#ga8714c4a5105d4130fb67c76b0d9a1920">cy_en_nnlite_status_t</a></td></tr>
  </table>
  </dd>
</dl>
<p>Byte block copy using NNLite.</p>
<p >Callback function from kernel config structure will be called after completion of layer. Kernel config structure should point to valid callback function.</p>
<p >Internally implemented as "depthwise" operation on 1x1xC input</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">inData</td><td>rhs input tensor pointer (elts repeated if less elts than lhs)</td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">outData</td><td>output buffer pointer</td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">inoutDims</td><td>rhs argument and output.</td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">actParams</td><td>unfused activation op params (lhs and output rescaling factors)</td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">act_type</td><td>Activation function to apply.</td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">intrplParam</td><td>interpolation param for PWL output activation , null = nothing set</td></tr>
  </table>
  </dd>
</dl>
<dl class="retval"><dt>Return values</dt><dd>
  <table class="retval">
    <tr><td class="paramname">Refer</td><td><a class="el" href="group__group__nnlite__enums.html#ga8714c4a5105d4130fb67c76b0d9a1920">cy_en_nnlite_status_t</a></td></tr>
  </table>
  </dd>
</dl>
<p>Byte block copy using NNLite</p>
<p >Internally implemented as "depthwise" operation on 1x1xC input</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">inData</td><td>address start byte vector to be copied</td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">outData</td><td>destination start address</td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">count</td><td>Number of bytes to be copied</td></tr>
  </table>
  </dd>
</dl>
<dl class="retval"><dt>Return values</dt><dd>
  <table class="retval">
    <tr><td class="paramname">Refer</td><td><a class="el" href="group__group__nnlite__enums.html#ga8714c4a5105d4130fb67c76b0d9a1920">cy_en_nnlite_status_t</a> </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="ga8f9de2b7fd88bf1cf4a5d312e5d629b5" name="ga8f9de2b7fd88bf1cf4a5d312e5d629b5"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ga8f9de2b7fd88bf1cf4a5d312e5d629b5">&#9670;&nbsp;</a></span>Cy_NNLite_Q31Reciprocal()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="group__group__nnlite__enums.html#ga8714c4a5105d4130fb67c76b0d9a1920">cy_en_nnlite_status_t</a> Cy_NNLite_Q31Reciprocal </td>
          <td>(</td>
          <td class="paramtype">const uint32_t *&#160;</td>
          <td class="paramname"><em>inData</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">float *&#160;</td>
          <td class="paramname"><em>outData</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="group__group__nn__kernel__data__structures.html#structcy__nn__dims__t">cy_nn_dims_t</a> *&#160;</td>
          <td class="paramname"><em>inoutDims</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Float reciprocal of (sums of) unsigned Q.31 values CPU mode kernel API. </p>
<p >Internally implemented as summing WxC input over the minor axis to produce W outputs</p>
<p >API will configure nnlite and then start nnlite operation. Callback function from kernel config structure will be called after completion of layer. Kernel config structure should point to valid callback function.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">inData</td><td>rhs input tensor pointer</td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">outData</td><td>output buffer pointer</td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">inoutDims</td><td>input values</td></tr>
  </table>
  </dd>
</dl>
<dl class="retval"><dt>Return values</dt><dd>
  <table class="retval">
    <tr><td class="paramname">Refer</td><td><a class="el" href="group__group__nnlite__enums.html#ga8714c4a5105d4130fb67c76b0d9a1920">cy_en_nnlite_status_t</a></td></tr>
  </table>
  </dd>
</dl>
<p>Internally implemented summing over the minor dimensions to produce W outputs from WxC inputs</p>
<p >API will configure nnlite and then start nnlite operation. Callback function from kernel config structure will be called after completion of layer. Kernel config structure should point to valid callback function.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">inData</td><td>rhs input tensor pointer</td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">outData</td><td>output buffer pointer</td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">inoutDims</td><td>input values dimensions</td></tr>
  </table>
  </dd>
</dl>
<dl class="retval"><dt>Return values</dt><dd>
  <table class="retval">
    <tr><td class="paramname">Refer</td><td><a class="el" href="group__group__nnlite__enums.html#ga8714c4a5105d4130fb67c76b0d9a1920">cy_en_nnlite_status_t</a> </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="gabd5ac089791284c715ad20d82bf66453" name="gabd5ac089791284c715ad20d82bf66453"></a>
<h2 class="memtitle"><span class="permalink"><a href="#gabd5ac089791284c715ad20d82bf66453">&#9670;&nbsp;</a></span>Cy_NNLite_LSTM_Int8()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="group__group__nnlite__enums.html#ga8714c4a5105d4130fb67c76b0d9a1920">cy_en_nnlite_status_t</a> Cy_NNLite_LSTM_Int8 </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="structcy__nn__lstm__context.html">cy_nn_lstm_context</a> *&#160;</td>
          <td class="paramname"><em>scratch_buffers</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int8_t *&#160;</td>
          <td class="paramname"><em>input_data</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="structcy__nn__lstm__dims.html">cy_nn_lstm_dims</a> *&#160;</td>
          <td class="paramname"><em>lstm_dims</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int8_t *&#160;</td>
          <td class="paramname"><em>input_to_input_weights</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int8_t *&#160;</td>
          <td class="paramname"><em>input_to_forget_weights</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int8_t *&#160;</td>
          <td class="paramname"><em>input_to_cell_weights</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int8_t *&#160;</td>
          <td class="paramname"><em>input_to_output_weights</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int8_t *&#160;</td>
          <td class="paramname"><em>recurrent_to_input_weights</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int8_t *&#160;</td>
          <td class="paramname"><em>recurrent_to_forget_weights</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int8_t *&#160;</td>
          <td class="paramname"><em>recurrent_to_cell_weights</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int8_t *&#160;</td>
          <td class="paramname"><em>recurrent_to_output_weights</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int8_t *&#160;</td>
          <td class="paramname"><em>projection_weights</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="structcy__nn__lstm__params.html">cy_nn_lstm_params</a> *&#160;</td>
          <td class="paramname"><em>lstm</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int8_t *&#160;</td>
          <td class="paramname"><em>output_state</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int16_t *&#160;</td>
          <td class="paramname"><em>cell_state</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int8_t *&#160;</td>
          <td class="paramname"><em>output_data</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>LSTM unidirectional function with 8 bit input and output and 16 bit gate output Peephole connections, projection, clipping, combined input/forget gate and layer normalization are not supported. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">scratch_buffers</td><td>Struct containing scratch buffers Expected size for each scratch buffer is lstm_dims-&gt;num_batches * lstm_dims-&gt;num_outputs. </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">input_data</td><td>Pointer to input data </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">lstm_dims</td><td>LSTM input parameters related to dimensions </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">input_to_input_weights</td><td>Input to input weights </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">input_to_forget_weights</td><td>Input to forget weights </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">input_to_cell_weights</td><td>Input to cell weights </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">input_to_output_weights</td><td>Input to output weights </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">recurrent_to_input_weights</td><td>Recurrent to input weights </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">recurrent_to_forget_weights</td><td>Recurrent to forget weights </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">recurrent_to_cell_weights</td><td>Recurrent to cell weights </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">recurrent_to_output_weights</td><td>Recurrent to output weights </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">projection_weights</td><td>Projection weights. Not used. </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">lstm</td><td>LSTM parameters. See struct declaration </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">output_state</td><td>Pointer to (recurrent) output state </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">cell_state</td><td>Pointer to cell state </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">output_data</td><td>Pointer to output state</td></tr>
  </table>
  </dd>
</dl>
<dl class="section note"><dt>Note</dt><dd>Derived from and API consistent with CMSIS-NN cy_nn_lstm_unidirectional_s16_s8 implementation for convenience. Following assumptions are done based on LSTM functionality as supported by Keras version 2.9.0 at the time of development. As stated here, <a href="https://github.com/tensorflow/community/blob/master/rfcs/20180920-unify-rnn-interface.md">https://github.com/tensorflow/community/blob/master/rfcs/20180920-unify-rnn-interface.md</a> Keras's LSTMCell is equivalent to TensorFlow's BasicLSTMCell, which does not support peephole, clipping or projection. <a class="el" href="structLayer.html">Layer</a> normalization and combined input/forget gate are not supported either.</dd></dl>
<p>1 Input to input weight can not be nullptr. Otherwise nullptr for combined input/forgat gate. 2 Cell weights are not used and should be nullptr. Otherwise needed for peephole connections. 3 Projection weight is not used and should be nullptr. Otherwise needed for projection.</p>
<dl class="section return"><dt>Returns</dt><dd>cy_en_nnlite_status_t Exit status (CY_NNLITE_SUCCESS for successful execution) </dd></dl>

</div>
</div>
<a id="gab3d27f971da724a7522c05ea5e2df014" name="gab3d27f971da724a7522c05ea5e2df014"></a>
<h2 class="memtitle"><span class="permalink"><a href="#gab3d27f971da724a7522c05ea5e2df014">&#9670;&nbsp;</a></span>Cy_NNLite_SoftMax_ScratchBufSize()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">uint32_t Cy_NNLite_SoftMax_ScratchBufSize </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="group__group__nn__kernel__data__structures.html#structcy__nn__dims__t">cy_nn_dims_t</a> *&#160;</td>
          <td class="paramname"><em>inoutDims</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="group__group__nnlite__enums.html#gab1d317e2be183e109725321de8c31bdb">cy_en_nnlite_activation_size_t</a>&#160;</td>
          <td class="paramname"><em>act_size</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Compute scratch buffer size needed to compute row-wise softmax of 2D input tensor. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">inoutDims</td><td>Input tensors dimensions (rows, cols) </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">act_size</td><td>Data element size of input </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>uint32_t Size of scratch buffer required in bytes</dd></dl>
<p>Compute scratch buffer size needed to compute row-wise softmax of 2D input tensor.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">inoutDims</td><td>Input dimensions of softmax operation </td></tr>
    <tr><td class="paramname">act_size</td><td>Size of input activation values </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>uint32_t Size of scratch buffer required </dd></dl>

</div>
</div>
<a id="gac54a6093cd8b0163aaaa07846f7b3a5a" name="gac54a6093cd8b0163aaaa07846f7b3a5a"></a>
<h2 class="memtitle"><span class="permalink"><a href="#gac54a6093cd8b0163aaaa07846f7b3a5a">&#9670;&nbsp;</a></span>Cy_NNLite_FC_ScratchBufSize()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">uint32_t Cy_NNLite_FC_ScratchBufSize </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="group__group__nn__kernel__data__structures.html#structcy__nn__dims__t">cy_nn_dims_t</a> *&#160;</td>
          <td class="paramname"><em>inDims</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="group__group__nn__kernel__data__structures.html#structcy__nn__dims__t">cy_nn_dims_t</a> *&#160;</td>
          <td class="paramname"><em>outDims</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Compute size scratch buffer required for FC op. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">inDims</td><td>input dimensions of FC operation </td></tr>
    <tr><td class="paramname">outDims</td><td>Output dimensions of FC operation </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>uint32_t Size of scratch buffer required </dd></dl>

</div>
</div>
<a id="ga8a96c7516ac63769ae913faa36a2732b" name="ga8a96c7516ac63769ae913faa36a2732b"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ga8a96c7516ac63769ae913faa36a2732b">&#9670;&nbsp;</a></span>Cy_NNLite_DMAModeScratchBufSize()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">uint32_t Cy_NNLite_DMAModeScratchBufSize </td>
          <td>(</td>
          <td class="paramtype">void&#160;</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Compute scratch buffer size needed for DMA mode API. </p>
<dl class="section return"><dt>Returns</dt><dd>uint32_t Size of scratch buffer required in bytes</dd></dl>
<p>Compute scratch buffer size needed for DMA mode API. </p>

</div>
</div>
<a id="ga0f1ab40879e8ec6bf78fac24502e08cb" name="ga0f1ab40879e8ec6bf78fac24502e08cb"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ga0f1ab40879e8ec6bf78fac24502e08cb">&#9670;&nbsp;</a></span>Cy_NNLite_TriggerDMAQueue()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="group__group__nnlite__enums.html#ga8714c4a5105d4130fb67c76b0d9a1920">cy_en_nnlite_status_t</a> Cy_NNLite_TriggerDMAQueue </td>
          <td>(</td>
          <td class="paramtype">void&#160;</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Cy_NNLite_TriggerDMAQueue will trigger DMA transfer of Queued layer starting from first queued layer, callback function will be called after completion of all the Queued layer if valid callback function is passed in kernel context, API will work in blocking mode if callback function is NULL. </p>
<dl class="retval"><dt>Return values</dt><dd>
  <table class="retval">
    <tr><td class="paramname">Refer</td><td><a class="el" href="group__group__nnlite__enums.html#ga8714c4a5105d4130fb67c76b0d9a1920">cy_en_nnlite_status_t</a> </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="ga2e7d7281eed1a4a04dc5e7198a286376" name="ga2e7d7281eed1a4a04dc5e7198a286376"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ga2e7d7281eed1a4a04dc5e7198a286376">&#9670;&nbsp;</a></span>Cy_NNLite_GetQueuedLayerCount()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">uint32_t Cy_NNLite_GetQueuedLayerCount </td>
          <td>(</td>
          <td class="paramtype">void&#160;</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Cy_NNLite_GetQueuedLayerCount will return count of queued layer for DMA. </p>
<dl class="retval"><dt>Return values</dt><dd>
  <table class="retval">
    <tr><td class="paramname">dmaQDepth</td><td>number of layers in DMA Queue </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="ga30aabc8d3c9ac00f08c73b3ad51c2f92" name="ga30aabc8d3c9ac00f08c73b3ad51c2f92"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ga30aabc8d3c9ac00f08c73b3ad51c2f92">&#9670;&nbsp;</a></span>Cy_NNLite_GetCurrDMAQueue()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="group__group__nnlite__enums.html#ga8714c4a5105d4130fb67c76b0d9a1920">cy_en_nnlite_status_t</a> Cy_NNLite_GetCurrDMAQueue </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="group__group__nn__kernel__data__structures.html#structcy__nnlite__dma__queue__config__t">cy_nnlite_dma_queue_config_t</a> *&#160;</td>
          <td class="paramname"><em>dmaQueue</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Cy_NNLite_GetCurrDMAQueue API will copy current dma queue in to dmaQueue pointer, valid dmaQueue pointer should be passed. </p>
<p >To get the runnable queue Cy_NNLite_GetCurrDMAQueue should be called after the created in Kernel DMA API such as Cy_NNLite_AvgpoolDMA and get executed by calling Cy_NNLite_TriggerDMAQueue</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">dmaQueue</td><td>dma queue pointer in which dma queue will be copied</td></tr>
  </table>
  </dd>
</dl>
<dl class="retval"><dt>Return values</dt><dd>
  <table class="retval">
    <tr><td class="paramname">Refer</td><td><a class="el" href="group__group__nnlite__enums.html#ga8714c4a5105d4130fb67c76b0d9a1920">cy_en_nnlite_status_t</a> </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="gaecab45a2c729ad12523ad57066f413f3" name="gaecab45a2c729ad12523ad57066f413f3"></a>
<h2 class="memtitle"><span class="permalink"><a href="#gaecab45a2c729ad12523ad57066f413f3">&#9670;&nbsp;</a></span>Cy_NNLite_RunDMAQueue()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="group__group__nnlite__enums.html#ga8714c4a5105d4130fb67c76b0d9a1920">cy_en_nnlite_status_t</a> Cy_NNLite_RunDMAQueue </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="group__group__nn__kernel__data__structures.html#structcy__nnlite__dma__queue__config__t">cy_nnlite_dma_queue_config_t</a> *&#160;</td>
          <td class="paramname"><em>dmaQueue</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Cy_NNLite_RunDMAQueue API will Trigger DMA dmaQueue queue valid dmaQueue pointer should be passed, DMA queue should return from Cy_NNLite_GetCurrDMAQueue queue will be in runnable state if Cy_NNLite_GetCurrDMAQueue called after queue created in Kernel DMA API such as Cy_NNLite_AvgpoolDMA and get executed by calling Cy_NNLite_TriggerDMAQueue. </p>
<p >API will work in blocking mode if callback function is passed as NULL in kernel context</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">dmaQueue</td><td>dma queue pointer in which dma queue will be copied</td></tr>
  </table>
  </dd>
</dl>
<dl class="retval"><dt>Return values</dt><dd>
  <table class="retval">
    <tr><td class="paramname">Refer</td><td><a class="el" href="group__group__nnlite__enums.html#ga8714c4a5105d4130fb67c76b0d9a1920">cy_en_nnlite_status_t</a> </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="gafe4dcd66f1780509daf8dc2a4657622e" name="gafe4dcd66f1780509daf8dc2a4657622e"></a>
<h2 class="memtitle"><span class="permalink"><a href="#gafe4dcd66f1780509daf8dc2a4657622e">&#9670;&nbsp;</a></span>Cy_NNLite_SoftMax()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="group__group__nnlite__enums.html#ga8714c4a5105d4130fb67c76b0d9a1920">cy_en_nnlite_status_t</a> Cy_NNLite_SoftMax </td>
          <td>(</td>
          <td class="paramtype">const int8_t *&#160;</td>
          <td class="paramname"><em>inData</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int8_t *&#160;</td>
          <td class="paramname"><em>outData</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int8_t *&#160;</td>
          <td class="paramname"><em>scratchBuf</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="group__group__nn__kernel__data__structures.html#structcy__nn__dims__t">cy_nn_dims_t</a> *&#160;</td>
          <td class="paramname"><em>inoutDims</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="group__group__nn__kernel__data__structures.html#structcy__nn__pwise__unary__params__t">cy_nn_pwise_unary_params_t</a> *&#160;</td>
          <td class="paramname"><em>smParams</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Compute row-wise softmax of 2D input tensor. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">inData</td><td></td></tr>
    <tr><td class="paramname">outData</td><td></td></tr>
    <tr><td class="paramname">expTempBuf</td><td></td></tr>
    <tr><td class="paramname">inoutDims</td><td></td></tr>
    <tr><td class="paramname">smParams</td><td></td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>cy_en_nnlite_status_t</dd></dl>
<p>Compute row-wise softmax of 2D input tensor.</p>
<dl class="section note"><dt>Note</dt><dd>This is a "macro" kernel requiring multiple primitive NNLite operations to compute.</dd></dl>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">inData</td><td>Input tensor data </td></tr>
    <tr><td class="paramname">outData</td><td>Output tensor data (MUST be distinct from <code>inData</code>) </td></tr>
    <tr><td class="paramname">scratchBuf</td><td>Scratch buffer for intermediate values (required size returned by <code>Cy_NNLite_SoftMax_ScratchBufSize</code>) (should be word-aligned for performance) </td></tr>
    <tr><td class="paramname">inoutDims</td><td>Dimensions of 2D input tensors (Set dim[0]==1 for 1D case) </td></tr>
    <tr><td class="paramname">smParams</td><td>Input/output tensor quantization parameters bitwidths etc. </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>cy_en_nnlite_status_t </dd></dl>

</div>
</div>
<a id="ga98348ccbe6152350b2991171ad1b92c0" name="ga98348ccbe6152350b2991171ad1b92c0"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ga98348ccbe6152350b2991171ad1b92c0">&#9670;&nbsp;</a></span>Cy_NNLite_FFT()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="group__group__nnlite__enums.html#ga8714c4a5105d4130fb67c76b0d9a1920">cy_en_nnlite_status_t</a> Cy_NNLite_FFT </td>
          <td>(</td>
          <td class="paramtype">int32_t *&#160;</td>
          <td class="paramname"><em>ppBuf0</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int32_t *&#160;</td>
          <td class="paramname"><em>ppBuf1</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">unsigned int&#160;</td>
          <td class="paramname"><em>fftStages</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Compute Q1.15 complex FFT. </p>
<p >NNLite implements Decimation-in-Time Radix-2 FFT for 16 bit input buffers should be allocated for 32 bit, buffers will be used in ping-pong mode final output will be in buf0 for even stage for odd stage buf1 will have final output </p><dl class="section note"><dt>Note</dt><dd>FFT length =^= Number complex input values *2 = # </dd></dl>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">ppBuf0</td><td>Input / ping-pong buffer 0, Output (even stages/# values) </td></tr>
    <tr><td class="paramname">ppBuf1</td><td>ping-pong buffer 1, Output (odd stages/# values) </td></tr>
    <tr><td class="paramname">fftStages</td><td>log_2(FFT length)</td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>cy_en_nnlite_status_t </dd></dl>

</div>
</div>
<a id="gad35f48e879493c686af5e10c956c8901" name="gad35f48e879493c686af5e10c956c8901"></a>
<h2 class="memtitle"><span class="permalink"><a href="#gad35f48e879493c686af5e10c956c8901">&#9670;&nbsp;</a></span>Cy_NNLite_FFTDMA()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="group__group__nnlite__enums.html#ga8714c4a5105d4130fb67c76b0d9a1920">cy_en_nnlite_status_t</a> Cy_NNLite_FFTDMA </td>
          <td>(</td>
          <td class="paramtype">int32_t *&#160;</td>
          <td class="paramname"><em>ppBuf0</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int32_t *&#160;</td>
          <td class="paramname"><em>ppBuf1</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">unsigned int&#160;</td>
          <td class="paramname"><em>fftStages</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">void *&#160;</td>
          <td class="paramname"><em>scratchBuf</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Compute Q1.15 complex FFT DMA mode API API will configure DMA descriptor pointing nnlite MEMIO configuration structure. </p>
<p >Valid scratchBuf should be passed in pParam, scratch buffer will be used for nnlite MEMIO configuration structure, size of scratch buffer should be value return from Cy_NNLite_ScratchBufSize. CY_NNLITE_OP_QUEUED will be the return value on success After queuing kernel, DMA needs to be triggered by calling API Cy_TriggerNNLiteDMAQueue</p>
<p >NNLite implements Decimation-in-Time Radix-2 FFT</p>
<dl class="section note"><dt>Note</dt><dd>FFT length =^= Number complex input values *2 = # </dd></dl>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">ppBuf0</td><td>Input / ping-pong buffer 0, Output (even stages/# values) </td></tr>
    <tr><td class="paramname">ppBuf1</td><td>ping-pong buffer 1, Output (odd stages/# values) </td></tr>
    <tr><td class="paramname">fftStages</td><td>log_2(FFT length) </td></tr>
    <tr><td class="paramname">scratchBuf</td><td>Scratch buffer for DMA mode</td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>cy_en_nnlite_status_t </dd></dl>

</div>
</div>
<a id="ga80cc663bc1668fe1a9167335e8985173" name="ga80cc663bc1668fe1a9167335e8985173"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ga80cc663bc1668fe1a9167335e8985173">&#9670;&nbsp;</a></span>Cy_NNLite_KernelInit()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="group__group__nnlite__enums.html#ga8714c4a5105d4130fb67c76b0d9a1920">cy_en_nnlite_status_t</a> Cy_NNLite_KernelInit </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="group__group__nn__kernel__data__structures.html#structcy__kernel__config__t">cy_kernel_config_t</a> *&#160;</td>
          <td class="paramname"><em>kernelConfig</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Kernel Init API, initialize PDL driver and setup IRQ handler, setup function pointers from kernelConfig argument. </p>
<p >This API needs to be called before calling any other kernel API</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">kernelConfig</td><td>kernel configuration structure</td></tr>
  </table>
  </dd>
</dl>
<dl class="retval"><dt>Return values</dt><dd>
  <table class="retval">
    <tr><td class="paramname">cy_en_nnlite_status_t</td><td></td></tr>
  </table>
  </dd>
</dl>
<p>Kernel Init API, initialize PDL driver and setup IRQ handler, setup function pointers from kernelConfig argument.</p>
<p >KernelConfig should have valid pointer for Mutex variable and function pointers for mutexCreate, mutexDelete, mutexLock, mutexUnlock and and should have valid pointers for Semaphore variable and function pointers for SemCreate, SemDelete, SemWait and SemGive for synchronization primitives. This API will allocate mutex and semaphore by calling mutexCreate and SemCreate, and will use them in successive call to other kernel public API's. API needs to be called before calling any other kernel API, If any of the pointers in KernelConfig is not valid API will return error code ,return value of API should be check to confirm successful initialization.</p>
<p >[in] kernelConfig kernel function pointers configuration structure </p>

</div>
</div>
<a id="gaf938f97f72466428554fe4694cc25722" name="gaf938f97f72466428554fe4694cc25722"></a>
<h2 class="memtitle"><span class="permalink"><a href="#gaf938f97f72466428554fe4694cc25722">&#9670;&nbsp;</a></span>Cy_NNLite_KernelDeInit()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="group__group__nnlite__enums.html#ga8714c4a5105d4130fb67c76b0d9a1920">cy_en_nnlite_status_t</a> Cy_NNLite_KernelDeInit </td>
          <td>(</td>
          <td class="paramtype">void&#160;</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Kernel Deinit API, de-initialize PDL driver and synchronization primitives. </p>
<p >needs re initialization after this API is called. Should be called only at end of program</p>
<dl class="retval"><dt>Return values</dt><dd>
  <table class="retval">
    <tr><td class="paramname">cy_en_nnlite_status_t</td><td></td></tr>
  </table>
  </dd>
</dl>
<p>needs re initialization after this API is called. Should be called only at end of program </p>

</div>
</div>
</div><!-- contents -->
</div><!-- doc-content -->
<!-- start footer part
<div id="nav-path" class="navpath">
    <ul>
        <li class="footer">
            Generated for <b>PSOC E8XXGP Device Support Library</b> by <b>Cypress Semiconductor Corporation</b>.
            All rights reserved.
        </li>
    </ul>
</div>
-->
</body>
</html>
